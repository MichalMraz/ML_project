{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michalmraz/Desktop/ML_project/ml_project_venv/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "from datasets import load_dataset\n",
    "# from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import requests\n",
    "import os\n",
    "import tarfile\n",
    "import re\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True  # slower but deterministic\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_causal_mask(seq_len):\n",
    "    # Create a matrix with ones in the lower triangle, zeros above\n",
    "    mask = torch.tril(torch.ones(seq_len, seq_len))\n",
    "    return mask  # shape (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, d_k):\n",
    "        super().__init__()\n",
    "        self.scale = d_k ** 0.5\n",
    "\n",
    "    def forward(self, Q, K, V, causal_mask=False, padding_mask=None):\n",
    "        # Q, K, V: (batch_size, num_heads, seq_len, d_k)\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / self.scale  # (B, H, L, L)\n",
    "\n",
    "        if causal_mask:\n",
    "            causal_mask = generate_causal_mask(scores.size(-1)).expand(scores.size(0), scores.size(1), -1, -1).to(scores.device)\n",
    "            scores = scores.masked_fill(causal_mask == 0, float('-inf'))\n",
    "        if padding_mask is not None:\n",
    "            padding_mask = padding_mask.unsqueeze(1).unsqueeze(2)  # (batch, 1, 1, seq_len)\n",
    "            scores = scores.masked_fill(padding_mask == 0, float('-inf'))  # Mask out pad positions\n",
    "\n",
    "        attention_weights = F.softmax(scores, dim=-1)  # (B, H, L, L)\n",
    "        output = torch.matmul(attention_weights, V)    # (B, H, L, d_k)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_embedding, num_heads, dropout=0):\n",
    "        super().__init__()\n",
    "        assert d_embedding % num_heads == 0\n",
    "        self.d_k = d_embedding // num_heads\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        #in reality these can map to a lower dimensional space to make things faster``\n",
    "        self.W_q = nn.Linear(d_embedding, d_embedding)\n",
    "        self.W_k = nn.Linear(d_embedding, d_embedding)\n",
    "        self.W_v = nn.Linear(d_embedding, d_embedding)\n",
    "        self.W_o = nn.Linear(d_embedding, d_embedding)\n",
    "\n",
    "        self.attention = ScaledDotProductAttention(self.d_k)\n",
    "\n",
    "        self.norm = nn.LayerNorm(d_embedding)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, causal_mask=False, padding_mask=None):\n",
    "        x_input = x\n",
    "        x = self.norm(x)\n",
    "\n",
    "        B, L, d_embedding = x.size()  # Batch, Sequence Length, Embedding Dim\n",
    "        H = self.num_heads\n",
    "\n",
    "        # Linear projections\n",
    "        Q = self.W_q(x).view(B, L, H, self.d_k).transpose(1, 2)  # (B, H, L, d_k)\n",
    "        K = self.W_k(x).view(B, L, H, self.d_k).transpose(1, 2)\n",
    "        V = self.W_v(x).view(B, L, H, self.d_k).transpose(1, 2)\n",
    "\n",
    "        # Apply attention\n",
    "        context = self.attention(Q, K, V, causal_mask, padding_mask)  # (B, H, L, d_k)\n",
    "\n",
    "        # Concatenate heads\n",
    "        context = context.transpose(1, 2).contiguous().view(B, L, d_embedding)  # (B, L, d_embedding)\n",
    "\n",
    "        # Final linear projection\n",
    "        output = self.W_o(context)  # (B, L, d_embedding)\n",
    "        output = self.dropout(output)\n",
    "\n",
    "        # Add (& pre-Norm)\n",
    "        #my preference is to do pre-norm for better stabiliy, even though the original paper used post-norm\n",
    "        output = x_input + output\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadCrossAttention(nn.Module):\n",
    "    def __init__(self, d_embedding, num_heads, dropout=0):\n",
    "        super().__init__()\n",
    "        assert d_embedding % num_heads == 0\n",
    "        self.d_k = d_embedding // num_heads\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.W_q = nn.Linear(d_embedding, d_embedding)\n",
    "        self.W_k = nn.Linear(d_embedding, d_embedding)\n",
    "        self.W_v = nn.Linear(d_embedding, d_embedding)\n",
    "        self.W_o = nn.Linear(d_embedding, d_embedding)\n",
    "\n",
    "        self.attention = ScaledDotProductAttention(self.d_k)\n",
    "\n",
    "        self.norm = nn.LayerNorm(d_embedding)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x_decoder, x_encoder, causal_mask=False, padding_mask=None):\n",
    "        assert x_decoder.size() == x_encoder.size() #x and x_encoder must have the same size\n",
    "        x_input = x_decoder\n",
    "        x_decoder = self.norm(x_decoder)\n",
    "        \n",
    "        B, L, d_embedding = x_decoder.size()  # Batch, Sequence Length, Embedding Dim\n",
    "        H = self.num_heads\n",
    "\n",
    "        # Linear projections\n",
    "        Q = self.W_q(x_decoder).view(B, L, H, self.d_k).transpose(1, 2)  # (B, H, L, d_k)\n",
    "        K = self.W_k(x_encoder).view(B, L, H, self.d_k).transpose(1, 2)\n",
    "        V = self.W_v(x_encoder).view(B, L, H, self.d_k).transpose(1, 2)\n",
    "\n",
    "        # Apply attention\n",
    "        context = self.attention(Q, K, V, causal_mask, padding_mask)  # (B, H, L, d_k)\n",
    "\n",
    "        # Concatenate heads\n",
    "        context = context.transpose(1, 2).contiguous().view(B, L, d_embedding)  # (B, L, d_embedding)\n",
    "\n",
    "        # Final linear projection\n",
    "        output = self.W_o(context)  # (B, L, d_embedding)\n",
    "        output = self.dropout(output)\n",
    "\n",
    "        output = output + x_input\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, d_embedding, d_ff, dropout=0):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_embedding, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_embedding)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.norm = nn.LayerNorm(d_embedding)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_input = x\n",
    "        x = self.norm(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x_input + x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_embedding, num_heads, d_ff, num_layers, dropout=0):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            MultiHeadAttention(d_embedding, num_heads, dropout=dropout),\n",
    "            FeedForwardNetwork(d_embedding, d_ff, dropout=dropout)\n",
    "        ] * num_layers)\n",
    "    \n",
    "    def forward(self, x, causal_mask=False, padding_mask=None):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if i % 2 == 0:\n",
    "                x = layer(x, causal_mask=causal_mask, padding_mask=padding_mask)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, encoder, d_embedding, num_heads, d_ff, num_layers, vocab_size, dropout=0):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.layers = nn.ModuleList([\n",
    "            MultiHeadAttention(d_embedding, num_heads, dropout=dropout),\n",
    "            MultiHeadCrossAttention(d_embedding, num_heads, dropout=dropout),\n",
    "            FeedForwardNetwork(d_embedding, d_ff, dropout=dropout)\n",
    "        ] * num_layers)\n",
    "        self.linear = nn.Linear(d_embedding, vocab_size)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x_decoder, x_encoder, causal_mask=False, encoder_padding_mask=None, decoder_padding_mask=None, inference=False):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if i % 3 == 0:\n",
    "                x_decoder = layer(x_decoder, causal_mask=causal_mask, padding_mask=decoder_padding_mask)\n",
    "            elif i % 3 == 1:\n",
    "                x_decoder = layer(x_decoder, x_encoder, causal_mask=False, padding_mask=encoder_padding_mask)\n",
    "            else:\n",
    "                x_decoder = layer(x_decoder)\n",
    "        x_decoder = self.linear(x_decoder)\n",
    "        if inference:\n",
    "            x_decoder = self.softmax(x_decoder)\n",
    "        return x_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, d_embedding, max_len, dropout=0): \n",
    "        #max_len is the maximum length of the input sequence\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Parameter(torch.randn(vocab_size, d_embedding))\n",
    "\n",
    "        pe = torch.zeros(max_len, d_embedding)\n",
    "        powers = torch.repeat_interleave(torch.arange(0, 1, 2/d_embedding), repeats=2).expand(max_len, -1)\n",
    "        divisors = torch.pow(10000, powers)\n",
    "        positions = torch.arange(0, max_len).view(max_len, -1).expand(-1, d_embedding)\n",
    "        args = positions / divisors\n",
    "        pe[:, 0::2] = torch.sin(args[:, 0::2])\n",
    "        pe[:, 1::2] = torch.cos(args[:, 1::2])\n",
    "\n",
    "        # Register as buffer so it's not a parameter but moves with `.to(device)`\n",
    "        self.register_buffer('pe', pe)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor of shape (batch_size, seq_len)\n",
    "        Returns:\n",
    "            Tensor of shape (batch_size, seq_len, d_embedding)\n",
    "        \"\"\"\n",
    "        seq_len = x.size(1)\n",
    "        # Add positional encoding: broadcast over batch dimension\n",
    "        x = self.embedding[x] + self.pe[:seq_len]\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(padded_input, pad_token_id=0):\n",
    "    return (padded_input != pad_token_id).int()  # shape: (batch, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_embedding, num_heads, d_ff, num_layers, max_len, dropout=0):\n",
    "        super().__init__()\n",
    "        self.embedding = Embedding(vocab_size, d_embedding, max_len, dropout=dropout)\n",
    "        self.encoder = Encoder(d_embedding, num_heads, d_ff, num_layers, dropout=dropout)\n",
    "        self.decoder = Decoder(self.encoder, d_embedding, num_heads, d_ff, num_layers, vocab_size, dropout=dropout)\n",
    "\n",
    "    def forward(self, x_encoder, x_decoder, causal_mask=False):\n",
    "        encoder_padding_mask = create_padding_mask(x_encoder)\n",
    "        decoder_padding_mask = create_padding_mask(x_decoder)\n",
    "\n",
    "        x_encoder = self.embedding(x_encoder)\n",
    "        x_decoder = self.embedding(x_decoder)\n",
    "        x_encoder = self.encoder(x_encoder, causal_mask=False, padding_mask=encoder_padding_mask)\n",
    "        output = self.decoder(x_decoder, x_encoder, causal_mask=causal_mask, encoder_padding_mask=encoder_padding_mask, decoder_padding_mask=decoder_padding_mask)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = load_dataset('opus_books', 'en-sk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the name of the model whose tokenizer we are using. We will need it later.\n",
    "PRE_TRAINED_MODEL_NAME = \"distilbert/distilbert-base-multilingual-cased\"\n",
    "\n",
    "# Download the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "vocab_size = tokenizer.vocab_size #119547\n",
    "max_len = 128\n",
    "d_embedding = 256\n",
    "d_ff = 1024\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "dropout=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dont_have_presaved_data = False\n",
    "#only set to true if I don't have 'tokenized_dataset_tensor.pt' in the current folder. Takes 15 min in total to download and tokenize the dataset\n",
    "\n",
    "if dont_have_presaved_data:\n",
    "    url = \"http://www.statmt.org/europarl/v7/sk-en.tgz\"\n",
    "    filename = \"sk-en.tgz\"\n",
    "\n",
    "    if not os.path.exists(filename):\n",
    "        r = requests.get(url)\n",
    "        with open(filename, \"wb\") as w:\n",
    "            w.write(r.content)\n",
    "        print(\"File downloaded\")\n",
    "    else:\n",
    "        print(\"File already exists\")\n",
    "    # Open a gzipped tar file in read mode\n",
    "    with tarfile.open(\"sk-en.tgz\", \"r:gz\") as tar:\n",
    "        # Get a TarFile object for the archive\n",
    "        # Extract all the files and directories to the current folder\n",
    "        tar.extractall()\n",
    "    # Define a function for text cleaning\n",
    "    def clean_text(text):\n",
    "\n",
    "        # Convert text to lowercase\n",
    "        text = str(text).lower().strip()\n",
    "\n",
    "        # Remove the \\n at the end of each line in the file\n",
    "        text = text.rstrip('\\n')\n",
    "\n",
    "        # Remove HTML tags and non-alphanumeric characters\n",
    "        text = re.sub(r\"<[^>]+>\", \"\", text)\n",
    "        text = re.sub(r\"[^a-zA-ZÀ-ž0-9\\s.,;!?':()\\[\\]{}-]\", \" \", text)  # Keep selected punctuation marks, symbols and apostrophes\n",
    "\n",
    "        # Remove excessive whitespace (more than one space)\n",
    "        text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "        text = text.encode(\"utf-8\", errors=\"ignore\").decode(\"utf-8\")  # Corrected encoding\n",
    "\n",
    "        return text\n",
    "    \n",
    "    # Read from the two text files, and create a pandas Series object (like a python list[]), and clean the text by\n",
    "    # applying our clean_text function to every element.\n",
    "\n",
    "    with open('europarl-v7.sk-en.en', 'r') as en_file, open('europarl-v7.sk-en.sk', 'r') as sk_file:\n",
    "        en = pd.Series(en_file.readlines(), name='en').apply(lambda text: clean_text(text))\n",
    "        sk = pd.Series(sk_file.readlines(), name='sk').apply(lambda text: clean_text(text))\n",
    "    translation_df = pd.concat([en, sk], axis=1)\n",
    "\n",
    "    # this takes over 10 min so I save the result and load it\n",
    "    tokenized = [{\n",
    "        'en': tokenizer.encode(translation_df.loc[i,'en'], return_tensors='pt', padding='max_length', max_length=max_len, truncation=True, add_special_tokens=True),\n",
    "        'sk': tokenizer.encode(translation_df.loc[i,'sk'], return_tensors='pt', padding='max_length', max_length=max_len, truncation=True, add_special_tokens=True)\n",
    "    } for i in range(translation_df.shape[0])]\n",
    "\n",
    "\n",
    "    # First, separate English and Slovak tensors\n",
    "    en_tensors = [item['en'] for item in tokenized]  \n",
    "    sk_tensors = [item['sk'] for item in tokenized]  \n",
    "\n",
    "    # Stack them into 3D tensors (num_sentences, max_len)\n",
    "    en_tensor = torch.stack(en_tensors)\n",
    "    sk_tensor = torch.stack(sk_tensors)\n",
    "    tokenized_dataset_tensor = torch.stack([en_tensor, sk_tensor])\n",
    "    torch.save(tokenized_dataset_tensor, 'tokenized_dataset_tensor.pt')\n",
    "else:\n",
    "    tokenized_dataset_tensor = torch.load('tokenized_dataset_tensor.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy input extras\n",
    "seq_len = 5\n",
    "batch_size = 2\n",
    "\n",
    "x_test = torch.randn(batch_size, seq_len, d_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    vocab_size=vocab_size,\n",
    "    d_embedding=d_embedding,\n",
    "    num_heads=num_heads,\n",
    "    d_ff=d_ff,\n",
    "    num_layers=num_layers,\n",
    "    max_len=max_len,\n",
    "    dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_len in dataset is 566 but I'm happy to go with 512 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, tokenized_dataset_tensor):\n",
    "        self.tokenized_dataset_tensor = tokenized_dataset_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.tokenized_dataset_tensor.shape[1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.tokenized_dataset_tensor[0][idx], self.tokenized_dataset_tensor[1][idx])\n",
    "        # 0 for English, 1 for Slovak\n",
    "\n",
    "dataset = TranslationDataset(tokenized_dataset_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cel = torch.nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), betas=(0.9, 0.98), eps=1e-9, lr=1e-4) #betas and eps from the original paper\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=1e-4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_accumulation_steps = 5\n",
    "warmup_steps = 100 / gradient_accumulation_steps\n",
    "\n",
    "def lr_lambda(step_num): #lr decay from original paper. We use fewer warmups\n",
    "    step_num = step_num + 1 #to avoid division by zero warning at step 0\n",
    "    # return min(1/np.sqrt(step_num), step_num / math.pow(warmup_steps, 1.5)) / np.sqrt(d_embedding) #og paper lr decay\n",
    "    #default inverse square root decay at 0.5\n",
    "    decay_speed = 0.3\n",
    "    # return min(math.pow(step_num, -decay_speed), step_num * math.pow(warmup_steps, -(1+decay_speed))) / np.sqrt(d_embedding) #og paper lr decay\n",
    "    return min(math.pow(step_num, -decay_speed), step_num * math.pow(warmup_steps, -(1+decay_speed))) * 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAHHCAYAAAC2rPKaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABnaklEQVR4nO3dd3gU1foH8O/sZndTN6SQBEhIaNJDFQhKUUoo0uRaEAUEsVwQBERFr9JUkCJ2BEXi7yqionBVigQkIBKVXiUUAxFIgfS62XJ+f2yyZElCdsMuW/L9PE+eZM6cmXnf2Uhez5yZkYQQAkRERERuSOboAIiIiIjshYUOERERuS0WOkREROS2WOgQERGR22KhQ0RERG6LhQ4RERG5LRY6RERE5LZY6BAREZHbYqFDREREbouFDhHdsqioKEyYMMHRYbiECxcuQJIkxMXFOToUojqBhQ6Rk4iLi4MkSThw4ICjQ6lTioqKMG/ePCQkJDg6FCKyAw9HB0BEri8pKQkymWv+f1NRURHmz58PAOjbt69jgyEim2OhQ0RmdDodDAYDlEqlxduoVCo7RmSd2sRPRO7LNf8XjKgOu3z5MiZOnIjQ0FCoVCq0bdsWn332mVmf0tJSvPbaa+jSpQv8/f3h4+ODXr16YdeuXWb9yueLLFu2DO+88w6aNWsGlUqFU6dOYd68eZAkCefOncOECRNQr149+Pv74/HHH0dRUZHZfm6co1N+Ge63337DzJkzUb9+ffj4+GDUqFG4evWq2bYGgwHz5s1Dw4YN4e3tjXvuuQenTp2yaN7PzeK35BxcuHAB9evXBwDMnz8fkiRBkiTMmzfP1Of06dP417/+hcDAQHh6eqJr16744YcfavqYAAA5OTmYMGEC/P39Ua9ePYwfPx45OTlV9rX0ODk5OZgxYwaioqKgUqkQHh6OcePG4dq1awAs++yFEIiKisKIESMq7b+kpAT+/v546qmnLMqRyNlxRIfIhaSnp6NHjx6QJAlTp05F/fr1sXXrVkyaNAl5eXl47rnnAAB5eXn49NNPMWbMGEyePBn5+flYs2YNYmNj8eeff6Jjx45m+127di1KSkrw5JNPQqVSITAw0LTuwQcfRJMmTbBo0SIcOnQIn376KUJCQvDWW2/VGO+zzz6LgIAAzJ07FxcuXMA777yDqVOn4uuvvzb1mTNnDpYsWYJhw4YhNjYWR48eRWxsLEpKSiw+L1XFb8k5qF+/PlauXIlnnnkGo0aNwv333w8AiI6OBgCcPHkSd911Fxo1aoSXXnoJPj4++OabbzBy5Eh89913GDVqVLUxCSEwYsQI7N27F08//TRat26NjRs3Yvz48ZX6WnqcgoIC9OrVC3/99RcmTpyIzp0749q1a/jhhx9w6dIlBAcHW5S3JEl49NFHsWTJEmRlZZl93j/++CPy8vLw6KOPWnz+iZyaICKnsHbtWgFA7N+/v9o+kyZNEg0aNBDXrl0za3/44YeFv7+/KCoqEkIIodPphEajMeuTnZ0tQkNDxcSJE01tycnJAoBQq9UiIyPDrP/cuXMFALP+QggxatQoERQUZNYWGRkpxo8fXymX/v37C4PBYGqfMWOGkMvlIicnRwghRFpamvDw8BAjR44029+8efMEALN9VuVm8Vt6Dq5evSoAiLlz51baf79+/UT79u1FSUmJqc1gMIiePXuKFi1a3DS2TZs2CQBiyZIlZjH16tVLABBr1661+jivvfaaACC+//77SscrP8+W5p2UlCQAiJUrV5r1HT58uIiKijL73IhcGS9dEbkIIQS+++47DBs2DEIIXLt2zfQVGxuL3NxcHDp0CAAgl8tNc1QMBgOysrKg0+nQtWtXU5+KRo8ebbqEc6Onn37abLlXr17IzMxEXl5ejTE/+eSTkCTJbFu9Xo+LFy8CAHbu3AmdTod///vfZts9++yzNe67pvitPQc3ysrKwi+//IIHH3wQ+fn5pnOdmZmJ2NhYnD17FpcvX652+y1btsDDwwPPPPOMWUw35mbNcb777jt06NChypGk8vNsad533HEHunfvji+//NIslq1bt2Ls2LFmnxuRK+OlKyIXcfXqVeTk5GD16tVYvXp1lX0yMjJMP3/++edYvnw5Tp8+Da1Wa2pv0qRJpe2qaivXuHFjs+WAgAAAQHZ2NtRq9U1jvtm2AEwFT/Pmzc36BQYGmvpaorr4rTkHNzp37hyEEHj11Vfx6quvVtknIyMDjRo1qnLdxYsX0aBBA/j6+pq1t2zZstbHOX/+PEaPHl1j7JbmPW7cOEydOhUXL15EZGQkvv32W2i1Wjz22GM1HoPIVbDQIXIRBoMBAPDoo49WOc8DuD635IsvvsCECRMwcuRIzJ49GyEhIZDL5Vi0aBHOnz9faTsvL69qjyuXy6tsF0LUGPOtbGuNquK39hzcqPx8P//884iNja2yz40FWm3Y+jjW5P3www9jxowZ+PLLL/Hyyy/jiy++QNeuXSsVY0SujIUOkYuoX78+/Pz8oNfr0b9//5v23bBhA5o2bYrvv//e7BLE3Llz7R2mVSIjIwEYRzUqjjZkZmaaRn1qy9JzUN0lmqZNmwIAFApFjee7KpGRkdi5cycKCgrMRnWSkpJqfZxmzZrhxIkTN+1jzWcfGBiIoUOH4ssvv8TYsWPx22+/4Z133qkpNSKXwjk6RC5CLpdj9OjR+O6776r8Y1fxtu3ykZSKIyd//PEHEhMT7R+oFfr16wcPDw+sXLnSrP2DDz645X1beg68vb0BoNJt3yEhIejbty9WrVqF1NTUSvu/8Tb5Gw0ZMgQ6nc4sN71ej/fff7/Wxxk9ejSOHj2KjRs3VupXnqe1n/1jjz2GU6dOYfbs2ZDL5Xj44YdvmheRq+GIDpGT+eyzz7Bt27ZK7dOnT8fixYuxa9cudO/eHZMnT0abNm2QlZWFQ4cOYceOHcjKygIA3Hffffj+++8xatQoDB06FMnJyfj444/Rpk0bFBQU3O6UqhUaGorp06dj+fLlGD58OAYNGoSjR49i69atCA4OvqUJsZaeAy8vL7Rp0wZff/017rjjDgQGBqJdu3Zo164dPvzwQ9x9991o3749Jk+ejKZNmyI9PR2JiYm4dOkSjh49Wu3xhw0bhrvuugsvvfQSLly4gDZt2uD7779Hbm5upb6WHmf27NnYsGEDHnjgAUycOBFdunRBVlYWfvjhB3z88cfo0KGD1Z/90KFDERQUhG+//RaDBw9GSEhIrc85kVNy1O1eRGSu/Jbs6r7++ecfIYQQ6enpYsqUKSIiIkIoFAoRFhYm+vXrJ1avXm3al8FgEG+++aaIjIwUKpVKdOrUSfz0009i/PjxIjIy0tSv/PbspUuXVoqn/Pbyq1evVhlncnKyqa2628tvvFV+165dAoDYtWuXqU2n04lXX31VhIWFCS8vL3HvvfeKv/76SwQFBYmnn376pufsZvFbeg6EEGLfvn2iS5cuQqlUVrrV/Pz582LcuHEiLCxMKBQK0ahRI3HfffeJDRs23DQ2IYTIzMwUjz32mFCr1cLf31889thj4vDhw5VuL7fmOJmZmWLq1KmiUaNGQqlUivDwcDF+/HjTIwesybvcv//9bwFArFu3rsaciFyNJISNZwUSEd2inJwcBAQE4PXXX8crr7zi6HDc3owZM7BmzRqkpaWZLuURuQvO0SEihyouLq7UVj4hli/ZtL+SkhJ88cUXGD16NIscckuco0NEDvX1118jLi4OQ4YMga+vL/bu3YuvvvoKAwcOxF133eXo8NxWRkYGduzYgQ0bNiAzMxPTp093dEhEdsFCh4gcKjo6Gh4eHliyZAny8vJME5Rff/11R4fm1k6dOoWxY8ciJCQE7733XqX3nxG5C87RISIiIrfFOTpERETktljoEBERkduqc3N0DAYDrly5Aj8/P76dl4iIyEUIIZCfn4+GDRtCJrN8nKbOFTpXrlxBRESEo8MgIiKiWvjnn38QHh5ucf86V+j4+fkBMJ4otVpt031rtVps374dAwcOhEKhsOm+nYG75we4f47Mz/W5e47Mz/XZK8e8vDxERESY/o5bqs4VOuWXq9RqtV0KHW9vb6jVarf8BXb3/AD3z5H5uT53z5H5uT5752jttBNORiYiIiK3xUKHiIiI3BYLHSIiInJbLHSIiIjIbbHQISIiIrfFQoeIiIjcFgsdIiIiclssdIiIiMhtsdAhIiIit8VCh4iIiNwWCx0iIiJyWyx0iIiIyG2x0LEhnd4AncHRURAREVE5Fjo2NPDd3/DKATk0rHaIiIicAgsdG/onuxglegkXrhU6OhQiIiICCx27EI4OgIiIiAA4UaGzePFiSJKE55577qb9vv32W7Rq1Qqenp5o3749tmzZcnsCJCIiIpfjFIXO/v37sWrVKkRHR9+03759+zBmzBhMmjQJhw8fxsiRIzFy5EicOHHiNkVqGcEhHSIiIqfg8EKnoKAAY8eOxSeffIKAgICb9n333XcxaNAgzJ49G61bt8bChQvRuXNnfPDBB7cpWiIiInIlHo4OYMqUKRg6dCj69++P119//aZ9ExMTMXPmTLO22NhYbNq0qdptNBoNNBqNaTkvLw8AoNVqodVqax/4Teh0Orvt25HKc3LH3Mq5e47Mz/W5e47Mz/XZK8fa7s+hhc769etx6NAh7N+/36L+aWlpCA0NNWsLDQ1FWlpatdssWrQI8+fPr9S+fft2eHt7WxfwTRgvVxlPZ+LvifjnuM127XTi4+MdHYLduXuOzM/1uXuOzM/12TrHoqKiWm3nsELnn3/+wfTp0xEfHw9PT0+7HWfOnDlmo0B5eXmIiIjAwIEDoVarbXYcIQSe+934ofbo0QPREYE227ez0Gq1iI+Px4ABA6BQKBwdjl24e47Mz/W5e47Mz/XZK8fyKzLWclihc/DgQWRkZKBz586mNr1ejz179uCDDz6ARqOBXC432yYsLAzp6elmbenp6QgLC6v2OCqVCiqVqlK7QqGw6QcgKsxAlss93PYXGLD9uXNG7p4j83N97p4j83N9ts6xtvty2GTkfv364fjx4zhy5Ijpq2vXrhg7diyOHDlSqcgBgJiYGOzcudOsLT4+HjExMbcrbCIiInIhDhvR8fPzQ7t27czafHx8EBQUZGofN24cGjVqhEWLFgEApk+fjj59+mD58uUYOnQo1q9fjwMHDmD16tW3PX4iIiJyfg6/vfxmUlJSkJqaalru2bMn1q1bh9WrV6NDhw7YsGEDNm3aVKlgIiIiIgKc4PbyihISEm66DAAPPPAAHnjggdsTkBX4kEAiIiLn49QjOkRERES3goWOHXB0h4iIyDmw0LEDwfeXExEROQUWOkREROS2WOgQERGR22KhYyO8WEVEROR8WOjYAScjExEROQcWOkREROS2WOjYAQd0iIiInAMLHTvQ6Q2ODoGIiIjAQscuZDLJ0SEQERERWOjYjOAMZCIiIqfDQsceWPMQERE5BRY6dsA6h4iIyDmw0LEDXsYiIiJyDix07IBlDhERkXNgoUNERERui4WOHfDKFRERkXNgoWMjwuxnVjpERETOgIWOHXBEh4iIyDmw0CEiIiK3xUKHiIiI3BYLHSIiInJbLHTsgHN0iIiInAMLHRupWNzwrisiIiLnwELHDjiiQ0RE5BxY6NgB6xwiIiLnwELHDjiiQ0RE5BxY6BAREZHbYqFjB5yMTERE5BxY6NiIWXHDOoeIiMgpsNAhIiIit+XQQmflypWIjo6GWq2GWq1GTEwMtm7dWm3/uLg4SJJk9uXp6XkbI7YMB3SIiIicg4cjDx4eHo7FixejRYsWEELg888/x4gRI3D48GG0bdu2ym3UajWSkpJMy5Ik3a5wLSZ42xUREZFTcGihM2zYMLPlN954AytXrsTvv/9ebaEjSRLCwsJuR3hERETk4pxmjo5er8f69etRWFiImJiYavsVFBQgMjISERERGDFiBE6ePHkbo7QMx3OIiIicg0NHdADg+PHjiImJQUlJCXx9fbFx40a0adOmyr4tW7bEZ599hujoaOTm5mLZsmXo2bMnTp48ifDw8Cq30Wg00Gg0puW8vDwAgFarhVartVkeWq3e9LNOq7Ppvp1FeU7umFs5d8+R+bk+d8+R+bk+e+VY2/1JwsETSkpLS5GSkoLc3Fxs2LABn376KXbv3l1tsVORVqtF69atMWbMGCxcuLDKPvPmzcP8+fMrta9btw7e3t63HL8pFgPw/B/GunFyKz3aBXBch4iIyFaKiorwyCOPIDc3F2q12uLtHF7o3Kh///5o1qwZVq1aZVH/Bx54AB4eHvjqq6+qXF/ViE5ERASuXbtm1YmqiUarR7sFOwEAHz7UHgPbNbDZvp2FVqtFfHw8BgwYAIVC4ehw7MLdc2R+rs/dc2R+rs9eOebl5SE4ONjqQsfhl65uZDAYzAqTm9Hr9Th+/DiGDBlSbR+VSgWVSlWpXaFQ2PQD0FeY7iT3kLvtLzBg+3PnjNw9R+bn+tw9R+bn+mydY2335dBCZ86cORg8eDAaN26M/Px8rFu3DgkJCfj5558BAOPGjUOjRo2waNEiAMCCBQvQo0cPNG/eHDk5OVi6dCkuXryIJ554wpFpVOZUY2RERER1l0MLnYyMDIwbNw6pqanw9/dHdHQ0fv75ZwwYMAAAkJKSApns+khJdnY2Jk+ejLS0NAQEBKBLly7Yt2+fRfN5iIiIqO5xaKGzZs2am65PSEgwW16xYgVWrFhhx4hsgwM6REREzsFpnqPjTpxrejcREVHdxULHDgTHdIiIiJwCCx07MLDOISIicgosdOygUKNzdAhEREQEFjp24a2UOzoEIiIiAgsdu+ClKyIiIufAQsdGKt5p5WRv1SAiIqqzWOjYAcscIiIi58BCxw44oENEROQcWOjYAescIiIi58BCxw44R4eIiMg5sNCxA9Y5REREzoGFjo1UfO2DgZUOERGRU2ChYwcsc4iIiJwDCx074IAOERGRc2ChYxesdIiIiJwBCx074IgOERGRc2ChYwd81xUREZFzYKFjI2bvuuKlKyIiIqfAQscOOKJDRETkHFjo2AMn6RARETkFFjp2wDKHiIjIObDQsQMO6BARETkHFjp2wDqHiIjIObDQsQO+64qIiMg5sNCxkYqlDescIiIi58BCxw4yC0odHQIRERGBhY5d+Krkjg6BiIiIwELHLjzkPK1ERETOgH+R7YCTkYmIiJwDCx07YJ1DRETkHKwqdLRaLZo1a4a//vrLXvG4LFGhuuGIDhERkXOwqtBRKBQoKSmxVyxugy/1JCIicg5WX7qaMmUK3nrrLeh0uls++MqVKxEdHQ21Wg21Wo2YmBhs3br1ptt8++23aNWqFTw9PdG+fXts2bLlluOwNcERHSIiIqfgYe0G+/fvx86dO7F9+3a0b98ePj4+Zuu///57i/cVHh6OxYsXo0WLFhBC4PPPP8eIESNw+PBhtG3btlL/ffv2YcyYMVi0aBHuu+8+rFu3DiNHjsShQ4fQrl07a1OxG9Y5REREzsHqQqdevXoYPXq0TQ4+bNgws+U33ngDK1euxO+//15lofPuu+9i0KBBmD17NgBg4cKFiI+PxwcffICPP/7YJjHZAufoEBEROQerC521a9faIw7o9Xp8++23KCwsRExMTJV9EhMTMXPmTLO22NhYbNq0qdr9ajQaaDQa03JeXh4A48RqrVZ764GX0WqvX8rT6fU23bezKM/JHXMr5+45Mj/X5+45Mj/XZ68ca7s/qwsdANDpdEhISMD58+fxyCOPwM/PD1euXIFarYavr69V+zp+/DhiYmJQUlICX19fbNy4EW3atKmyb1paGkJDQ83aQkNDkZaWVu3+Fy1ahPnz51dq3759O7y9va2K9WaKdUD56Tz/dzK2bDlvs307m/j4eEeHYHfuniPzc33uniPzc322zrGoqKhW21ld6Fy8eBGDBg1CSkoKNBoNBgwYAD8/P7z11lvQaDRWX0Jq2bIljhw5gtzcXGzYsAHjx4/H7t27qy12rDVnzhyzUaC8vDxERERg4MCBUKvVNjkGAOSXaPHS/l0AgMioKAwZ1Mpm+3YWWq0W8fHxGDBgABQKhaPDsQt3z5H5uT53z5H5uT575Vh+RcZaVhc606dPR9euXXH06FEEBQWZ2keNGoXJkydbHYBSqUTz5s0BAF26dMH+/fvx7rvvYtWqVZX6hoWFIT093awtPT0dYWFh1e5fpVJBpVJValcoFDb9ADz013+WyWRu+wsM2P7cOSN3z5H5uT53z5H5uT5b51jbfVl9e/mvv/6K//znP1AqlWbtUVFRuHz5cq2CqMhgMJjNqakoJiYGO3fuNGuLj4+vdk6Po/A5OkRERM7B6hEdg8EAvV5fqf3SpUvw8/Ozal9z5szB4MGD0bhxY+Tn52PdunVISEjAzz//DAAYN24cGjVqhEWLFgEwjib16dMHy5cvx9ChQ7F+/XocOHAAq1evtjYNu+JzdIiIiJyD1SM6AwcOxDvvvGNaliQJBQUFmDt3LoYMGWLVvjIyMjBu3Di0bNkS/fr1w/79+/Hzzz9jwIABAICUlBSkpqaa+vfs2RPr1q3D6tWr0aFDB2zYsAGbNm1yqmfoABzRISIichZWj+gsX74csbGxaNOmDUpKSvDII4/g7NmzCA4OxldffWXVvtasWXPT9QkJCZXaHnjgATzwwANWHed2qDiIczW/6ktvREREdHtZXeiEh4fj6NGjWL9+PY4dO4aCggJMmjQJY8eOhZeXlz1idDkySXJ0CERERIRaPkfHw8MDjz76qK1jcRtqr1qdViIiIrIxi/4i//DDDxg8eDAUCgV++OGHm/YdPny4TQJzZXpO0iEiInIKFhU6I0eORFpaGkJCQjBy5Mhq+0mSVOUdWXUN33VFRETkHCwqdAwGQ5U/U9U4oENEROQcrL69nKpW8dk5vHRFRETkHCwa0Xnvvfcs3uG0adNqHYwrq3i1imUOERGRc7Co0FmxYoVFO5Mkqc4WOhUJjugQERE5BYsKneTkZHvH4VZY5xARETmHW5qjI4Tge52qoOc5ISIicgq1KnTWrFmDdu3awdPTE56enmjXrh0+/fRTW8fmslj8EREROQerH+H72muv4e2338azzz6LmJgYAEBiYiJmzJiBlJQULFiwwOZBuhredUVEROQcrC50Vq5ciU8++QRjxowxtQ0fPhzR0dF49tln62yhU7G0YZ1DRETkHKy+dKXVatG1a9dK7V26dIFOp7NJUK6OT0YmIiJyDlYXOo899hhWrlxZqX316tUYO3asTYJydSx0iIiInEOtXrO9Zs0abN++HT169AAA/PHHH0hJScG4ceMwc+ZMU7+3337bNlG6GL4lg4iIyDlYXeicOHECnTt3BgCcP38eABAcHIzg4GCcOHHC1E+SJBuF6Hp0nKRDRETkFKwudHbt2mWPONwKL10RERE5B77U00YqPjuHhQ4REZFzsGhE5/7770dcXBzUajXuv//+m/b9/vvvbRKYK+NzdIiIiJyDRYWOv7+/ac6NWq2u0/NvLME6h4iIyDlYVOisXbvW9HNcXJy9YnEbHNEhIiJyDlbP0bn33nuRk5NTqT0vLw/33nuvLWJyeZyjQ0RE5BysLnQSEhJQWlpaqb2kpAS//vqrTYJydRzRISIicg4W315+7Ngx08+nTp1CWlqaaVmv12Pbtm1o1KiRbaNzUadS8x0dAhEREcGKQqdjx46QJAmSJFV5icrLywvvv/++TYNzJRXHcBoHejksDiIiIrrO4kInOTkZQgg0bdoUf/75J+rXr29ap1QqERISArlcbpcgXY2cd6URERE5BYsLncjISACAgS9yqhFfAUFEROQcLCp0fvjhB4t3OHz48FoH4y44GZmIiMg5WFTojBw50qKdSZIEvV5/K/G4BT1vLyciInIKFhU6vFxlHY7oEBEROQe+1NNGKg7isNAhIiJyDhZPRi63YMGCm65/7bXXLN7XokWL8P333+P06dPw8vJCz5498dZbb6Fly5bVbhMXF4fHH3/crE2lUqGkpMTi49obJyMTERE5B6sLnY0bN5ota7VaJCcnw8PDA82aNbOq0Nm9ezemTJmCO++8EzqdDi+//DIGDhyIU6dOwcfHp9rt1Go1kpKSTMvO9pLR/BKdo0MgIiIi1KLQOXz4cKW2vLw8TJgwAaNGjbJqX9u2bTNbjouLQ0hICA4ePIjevXtXu50kSQgLC7PqWERERFT3WF3oVEWtVmP+/PkYNmwYHnvssVrvJzc3FwAQGBh4034FBQWIjIyEwWBA586d8eabb6Jt27ZV9tVoNNBoNKblvLw8AMaRKK1WW+tYb6TTXd+XTIJN9+0synNyx9zKuXuOzM/1uXuOzM/12SvH2u5PEsI290Lv3bsXw4YNQ3Z2dq22NxgMGD58OHJycrB3795q+yUmJuLs2bOIjo5Gbm4uli1bhj179uDkyZMIDw+v1H/evHmYP39+pfZ169bB29u7VrFWJa8UePXg9bpxRQ8dZM51RY2IiMhlFRUV4ZFHHkFubi7UarXF21ld6Lz33ntmy0IIpKam4r///S/69OmDdevWWbM7k2eeeQZbt27F3r17qyxYqqPVatG6dWuMGTMGCxcurLS+qhGdiIgIXLt2zaoTVZOr+Rr0XLLbtHxybn8oPdzrpjatVov4+HgMGDAACoXC0eHYhbvnyPxcn7vnyPxcn71yzMvLQ3BwsNWFjtWXrlasWGG2LJPJUL9+fYwfPx5z5syxdncAgKlTp+Knn37Cnj17rCpyAEChUKBTp044d+5cletVKhVUKlWV29nyA/BQmD8oUZLLoVDY5Mqg07H1uXNG7p4j83N97p4j83N9ts6xtvuy+i9xcnJyrQ5UFSEEnn32WWzcuBEJCQlo0qSJ1fvQ6/U4fvw4hgwZYrO4bEGr5y3mREREjubQIYcpU6Zg3bp1+N///gc/Pz+kpaUBAPz9/eHl5QUAGDduHBo1aoRFixYBMD7Hp0ePHmjevDlycnKwdOlSXLx4EU888YTD8qgKHxpIRETkeFYXOiUlJXj//fexa9cuZGRkVHo9xKFDhyze18qVKwEAffv2NWtfu3YtJkyYAABISUmBTHZ9rkt2djYmT56MtLQ0BAQEoEuXLti3bx/atGljbSp2pdPztRlERESOZnWhM2nSJGzfvh3/+te/0K1bt1t6WJ8l86ATEhLMllesWFFpnpAz0uhY6BARETma1YXOTz/9hC1btuCuu+6yRzxug5euiIiIHM/q+58bNWoEPz8/e8Ti2m6oa3R84zsREZHDWV3oLF++HC+++CIuXrxoj3jcRqmOIzpERESOZvWlq65du6KkpARNmzaFt7d3pfvas7KybBacK+OIDhERkeNZXeiMGTMGly9fxptvvonQ0FCne3O4s+BzdIiIiBzP6kJn3759SExMRIcOHewRj9vQ8vZyIiIih7N6jk6rVq1QXFxsj1jcSm6x+76ZloiIyFVYXegsXrwYs2bNQkJCAjIzM5GXl2f2VVfdeKFKIeclPSIiIkez+tLVoEGDAAD9+vUzaxdCQJIk6PX6qjarc3jXFRERkeNZXejs2rXLHnG4Hc7RISIicjyrC50+ffrYIw63w0KHiIjI8ayeo0OWyS7iZGQiIiJHY6FjJ8WlOkeHQEREVOex0LETT4Xc0SEQERHVeSx0bETccJNVKefoEBEROVytCh2dTocdO3Zg1apVyM/PBwBcuXIFBQUFNg3OlZXqWOgQERE5mtV3XV28eBGDBg1CSkoKNBoNBgwYAD8/P7z11lvQaDT4+OOP7RGnyynW8nlCREREjmb1iM706dPRtWtXZGdnw8vLy9Q+atQo7Ny506bBubLzGRzdIiIicjSrR3R+/fVX7Nu3D0ql0qw9KioKly9ftllgri7M39PRIRAREdV5Vo/oGAyGKl/zcOnSJfj5+dkkKHfAOTpERESOZ3WhM3DgQLzzzjumZUmSUFBQgLlz52LIkCG2jM2liBte66lhoUNERORwVl+6Wr58OWJjY9GmTRuUlJTgkUcewdmzZxEcHIyvvvrKHjG6pHOco0NERORwVhc64eHhOHr0KL7++mscPXoUBQUFmDRpEsaOHWs2ObmuU3nwEUVERESOZnWhs2fPHvTs2RNjx47F2LFjTe06nQ579uxB7969bRqgq1J58MnIREREjmb1sMM999yDrKysSu25ubm45557bBKUOyjR8Tk6REREjmZ1oSOEgCRJldozMzPh4+Njk6DcQUaextEhEBER1XkWX7q6//77ARjvspowYQJUKpVpnV6vx7Fjx9CzZ0/bR+gibnzX1ZXcYscEQkRERCYWFzr+/v4AjCM6fn5+ZhOPlUolevTogcmTJ9s+QhfVQM0HBhIRETmaxYXO2rVrARifgPz888/zMlUN+K4rIiIix7P6rqu5c+faIw63k12kdXQIREREdZ7VhQ4AbNiwAd988w1SUlJQWlpqtu7QoUM2CcwdGAwCMlnlidtERER0e1h919V7772Hxx9/HKGhoTh8+DC6deuGoKAg/P333xg8eLA9YnRZfA0EERGRY1ld6Hz00UdYvXo13n//fSiVSrzwwguIj4/HtGnTkJuba48YXYqswjuvOE+HiIjIsawudFJSUky3kXt5eSE/Px8A8Nhjj1n9rqtFixbhzjvvhJ+fH0JCQjBy5EgkJSXVuN23336LVq1awdPTE+3bt8eWLVusTcPmyssbSQKUZa9/KNToHBcQERERWV/ohIWFmZ6M3LhxY/z+++8AgOTkZIgbHyZTg927d2PKlCn4/fffER8fD61Wi4EDB6KwsLDabfbt24cxY8Zg0qRJOHz4MEaOHImRI0fixIkT1qZiFxKA0rJLVkWlHNEhIiJyJKsnI99777344Ycf0KlTJzz++OOYMWMGNmzYgAMHDpgeKmipbdu2mS3HxcUhJCQEBw8erPadWe+++y4GDRqE2bNnAwAWLlyI+Ph4fPDBB/j444+tTccuQvxUyMjX8NIVERGRg1ld6KxevRoGg3HEYsqUKQgKCsK+ffswfPhwPPXUU7cUTPkcn8DAwGr7JCYmYubMmWZtsbGx2LRpU5X9NRoNNJrrr2PIy8sDAGi1Wmi1trsFXFdhX74qOTLygaz8Ymi17vO8ofLzZcvz5mzcPUfm5/rcPUfm5/rslWNt9ycJK6436XQ6vPnmm5g4cSLCw8NrdcDqGAwGDB8+HDk5Odi7d2+1/ZRKJT7//HOMGTPG1PbRRx9h/vz5SE9Pr9R/3rx5mD9/fqX2devWwdvb2zbBA8jSAPMPecBDEvBVADmlEsa30KNzsHWX84iIiKiyoqIiPPLII8jNzYVarbZ4O6tGdDw8PLBkyRKMGzfO6gBrMmXKFJw4ceKmRU5tzJkzx2wEKC8vDxERERg4cKBVJ6omV3KKMf/QrwCAQLUPcq4VoUPHjhgS3cBmx3A0rVaL+Ph4DBgwAAqFwtHh2IW758j8XJ+758j8XJ+9ciy/ImMtqy9d9evXD7t370ZUVFStDliVqVOn4qeffsKePXtqHCkKCwurNHKTnp6OsLCwKvurVCqzF5CWUygUNv0A5B7Xh9Signzw97UipOWXuuUvsq3PnTNy9xyZn+tz9xyZn+uzdY613ZfVhc7gwYPx0ksv4fjx4+jSpUuld14NHz7c4n0JIfDss89i48aNSEhIQJMmTWrcJiYmBjt37sRzzz1naouPj0dMTIzFx7UnCdefn6PT87IVERGRI1ld6Pz73/8GALz99tuV1kmSBL3e8juNpkyZgnXr1uF///sf/Pz8kJaWBsD4pvTyt6OPGzcOjRo1wqJFiwAA06dPR58+fbB8+XIMHToU69evx4EDB7B69WprU7Gbel7GqlNvYKFDRETkSFY/R8dgMFT7ZU2RAwArV65Ebm4u+vbtiwYNGpi+vv76a1OflJQUpKammpZ79uyJdevWYfXq1ejQoQM2bNiATZs2oV27dtamYjeNAoxF2onLfFI0ERGRI9XqpZ62YskNXwkJCZXaHnjgATzwwAN2iMg2csreXB7oo3RwJERERHWb1SM6VLNWYb4AgPwSvgKCiIjIkVjo2IG30jhQduxSjmMDISIiquNY6NhIVVfhQv09b38gREREZMJCx9YkIKJsMvLhlBzHxkJERFTHWT0ZubonE0qSBJVKBaWSE3BVCmP9GMTJyERERA5ldaFTr149SJJU7frw8HBMmDABc+fOhUxWNweMgn2NBU5mYamDIyEiIqrbrC504uLi8Morr2DChAno1q0bAODPP//E559/jv/85z+4evUqli1bBpVKhZdfftnmAbsCtef1x1RrdHqoPOQOjIaIiKjusrrQ+fzzz7F8+XI8+OCDprZhw4ahffv2WLVqFXbu3InGjRvjjTfeqLOFjp/q+mnNK9ahvh8LHSIiIkew+trSvn370KlTp0rtnTp1QmJiIgDg7rvvRkpKyq1H56JkMgk+SmNxczVf4+BoiIiI6i6rC52IiAisWbOmUvuaNWsQEREBAMjMzERAQMCtR+eCymcvFZbqy77zoYFERESOYvWlq2XLluGBBx7A1q1bceeddwIADhw4gNOnT2PDhg0AgP379+Ohhx6ybaQupl0jNU5czkNKZhHujAp0dDhERER1ktWFzvDhw3H69GmsWrUKZ86cAQAMHjwYmzZtQlRUFADgmWeesWmQriirwHjHVYnOuhedEhERke3U6qWeTZo0weLFi20di1vpFBmAK8dSkXy10NGhEBER1Vm1KnRycnLw559/IiMjAwaDwWzduHHjbBKYqyvVGc/LtQJORiYiInIUqwudH3/8EWPHjkVBQQHUarXZwwMlSaqzhc6N77pqWt8HAKDRGaroTURERLeD1XddzZo1CxMnTkRBQQFycnKQnZ1t+srKyrJHjC4p2EcFADh2KdfBkRAREdVdVhc6ly9fxrRp0+Dt7W2PeNxGYNl7rtReihp6EhERkb1YXejExsbiwIED9ojFrTQpu3T1V2rVL0ElIiIi+7N6js7QoUMxe/ZsnDp1Cu3bt4dCYT5iMXz4cJsF58oCvK+/uVwIcdMXoRIREZF9WF3oTJ48GQCwYMGCSuskSYJez+fGAEADf0/Tz3nFOvh78xIWERHR7WZ1oXPj7eRUNU/F9Rd5Xs4pZqFDRETkAFbP0aGqCYhq12UXld7GSIiIiKicRSM67733Hp588kl4enrivffeu2nfadOm2SQwV1VxJk7PZkHYdz4T6XklDouHiIioLrOo0FmxYgXGjh0LT09PrFixotp+kiTV+UKnojC1cZ5OGgsdIiIih7Co0ElOTq7yZ7q5BvWMhU56LgsdIiIiR+AcHTsK8/cCAFxhoUNEROQQVt91pdfrERcXh507d1b5Us9ffvnFZsG5uoZlt5hfySl2cCRERER1k9WFzvTp0xEXF4ehQ4eiXbt2fBBemRtf6gkAjQKMIzqXWegQERE5hNWFzvr16/HNN99gyJAh9ojH9VWo+8IDjO8DyynSokCjg6/K6tNNREREt8DqOTpKpRLNmze3Ryxux1flgXplDwr8J6vIwdEQERHVPVYXOrNmzcK7774LUdW1GqokomxUh4UOERHR7Wf1tZS9e/di165d2Lp1K9q2bVvppZ7ff/+9zYJzB40DvXH8ci5SWOgQERHddlaP6NSrVw+jRo1Cnz59EBwcDH9/f7Mva+zZswfDhg1Dw4YNIUkSNm3adNP+CQkJkCSp0ldaWpq1adw2kUHGEZ0LmYUOjoSIiKjusWpER6fT4Z577sHAgQMRFhZ2ywcvLCxEhw4dMHHiRNx///0Wb5eUlAS1Wm1aDgkJueVYblV1F/Kign0AABeucUSHiIjodrOq0PHw8MDTTz+Nv/76yyYHHzx4MAYPHmz1diEhIahXr55NYrC1G2+2b1pW6CRf44gOERHR7Wb1HJ1u3brh8OHDiIyMtEc8FunYsSM0Gg3atWuHefPm4a677qq2r0ajgUajMS3n5eUBALRaLbRarc1i0umu76vifiPqqQAYn6WTW1gMb6Xr3mJenpctz5uzcfccmZ/rc/ccmZ/rs1eOtd2fJKy8feqbb77BnDlzMGPGDHTp0gU+Pj5m66Ojo2sXiCRh48aNGDlyZLV9kpKSkJCQgK5du0Kj0eDTTz/Ff//7X/zxxx/o3LlzldvMmzcP8+fPr9S+bt06eHt71yrWqmQUA28c8YCnXOCtbnqzdS/vl6NQJ+H59jpE+NrskERERHVGUVERHnnkEeTm5ppNX6mJ1YWOTFZ5/rIkSRBCQJIk6PX6KrayIBALCp2q9OnTB40bN8Z///vfKtdXNaITERGBa9euWXWianIhsxAD3vkNnnKBQ6/ca3Y32iNr9mP/hWwsHd0OIzs2tNkxbzetVov4+HgMGDCg0t127sLdc2R+rs/dc2R+rs9eOebl5SE4ONjqQsfq6yjO9vbybt26Ye/evdWuV6lUUKlUldoVCoVNPwAPj+v7unHfLcP8sP9CNs5fK3aLX2xbnztn5O45Mj/X5+45Mj/XZ+sca7svqwsdR87NqcqRI0fQoEEDR4dxUy3DjJXn6bQ8B0dCRERUt9R6ZuypU6eQkpKC0tJSs/bhw4dbvI+CggKcO3fOtJycnIwjR44gMDAQjRs3xpw5c3D58mX83//9HwDgnXfeQZMmTdC2bVuUlJTg008/xS+//ILt27fXNg2budkVwNZhfgCAv1JZ6BAREd1OVhc6f//9N0aNGoXjx4+b5uYAML3F3Jo5OgcOHMA999xjWp45cyYAYPz48YiLi0NqaipSUlJM60tLSzFr1ixcvnwZ3t7eiI6Oxo4dO8z24WhVvcu9VQM1JAlIz9PgWoEGwb6VL6URERGR7Vld6EyfPh1NmjTBzp070aRJE/z555/IzMzErFmzsGzZMqv21bdv35uOhMTFxZktv/DCC3jhhResDdnhfFUeaBLkg7+vFeLE5Vz0ben4BxwSERHVBVa/AiIxMRELFixAcHAwZDIZZDIZ7r77bixatAjTpk2zR4xuoV0j4+sxjl/KdXAkREREdYfVhY5er4efn3HOSXBwMK5cuQLAOEk5KSnJttG5kQ4R9QAARy/lODQOIiKiusTqS1ft2rXD0aNH0aRJE3Tv3h1LliyBUqnE6tWr0bRpU3vE6BY6RhhHdA6n5JieOURERET2ZXWh85///AeFhcb3Ni1YsAD33XcfevXqhaCgIHz99dc2D9BV1PTUxbYN/aGUy5BZWIqLmUWml30SERGR/Vhd6MTGxpp+bt68OU6fPo2srCwEBARwlOImPBVytA/3x8GL2dh/IYuFDhER0W1g9RydcufOncPPP/+M4uJiBAYG2jImt3VnlPE8/ZGc5eBIiIiI6garC53MzEz069cPd9xxB4YMGYLU1FQAwKRJkzBr1iybB+hOejQ1FjqJ5zNvels9ERER2YbVhc6MGTOgUCiQkpJi9vbvhx56CNu2bbNpcO7mzqhAeMgkXM4pRkpWkaPDISIicntWFzrbt2/HW2+9hfDwcLP2Fi1a4OLFizYLzB35qDzQuXEAAGDP2WsOjoaIiMj9WV3oFBYWmo3klMvKyqryLeFkrvcdwQCA3UkZDo6EiIjI/Vld6PTq1cv0kk3A+I4rg8GAJUuWONU7p243S6fclL/+4bdzmSjRWv5eMCIiIrKe1beXL1myBP369cOBAwdQWlqKF154ASdPnkRWVhZ+++03e8ToUmq6wb5tQzUa+HsiNbcEv527hn6tQ29LXERERHWR1SM67dq1w5kzZ3D33XdjxIgRKCwsxP3334/Dhw+jWbNm9ojRrUiShAFtjMXNzyfTHBwNERGRe7N6RAcA/P398corr5i1Xbp0CU8++SRWr15tk8Dc2aC2Yfi/xIvYfiodb+gNUMhr/TgjIiIiugmb/YXNzMzEmjVrbLU7t9a9aRCCfZXIKdJiL+++IiIishsOJTiAXCbhvuiGAICNhy87OBoiIiL3xULHZqx70vGoTo0AGOfp5BZr7REQERFRncdCx9YsfK9pdLg/7gj1hUZnwA9HOKpDRERkDxZPRr7//vtvuj4nJ+dWY6lTJEnCw3c2xoKfTuHLP1LwaI9Ivv2diIjIxiwudPz9/WtcP27cuFsOqC4Z3TkcS34+jdNp+fgjOQs9mgY5OiQiIiK3YnGhs3btWnvGUSf5eyswqlM4vvozBWv2JrPQISIisjHO0XGwSXdHAQB2/JWOcxkFjg2GiIjIzbDQsRFL33V1o+YhfhjQJhRCAB8lnLNtUERERHUcCx0bq8104qn3NAcAbDp8GX9f5agOERGRrbDQcQIdIuqhX6sQGASwPP6Mo8MhIiJyGyx0nMTzsS0hScDmY6k4nJLt6HCIiIjcAgsdJ9G6gRqjO4cDAOb/eAoGQy0n/RAREZEJCx0nMju2JXyUchz5JwffHPjH0eEQERG5PBY6TiRU7YkZA+4AACzaehoZ+SUOjoiIiMi1sdCxEVtdaJrQMwptG6qRW6zFfzaegKjtfetERETEQsfZeMhlWPqvDlDIJWw/lY4NBy85OiQiIiKXxULHCbVpqMZz/Y2XsOb+cBLn+WwdIiKiWnFoobNnzx4MGzYMDRs2hCRJ2LRpU43bJCQkoHPnzlCpVGjevDni4uLsHqcjPN2nGWKaBqGoVI9/f3EIRaU6R4dERETkchxa6BQWFqJDhw748MMPLeqfnJyMoUOH4p577sGRI0fw3HPP4YknnsDPP/9s50hvP7lMwrsPd0SwrwpJ6fmY/e0xztchIiKyksVvL7eHwYMHY/DgwRb3//jjj9GkSRMsX74cANC6dWvs3bsXK1asQGxsrL3CdJgQtSc+frQzxnzyOzYfT0XTeB/MGtjS0WERERG5DJeao5OYmIj+/fubtcXGxiIxMdFBEV1nr8GWrlGBeGNkewDA+7+cw7o/UuxzICIiIjfk0BEda6WlpSE0NNSsLTQ0FHl5eSguLoaXl1elbTQaDTQajWk5Ly8PAKDVaqHVam0Wm05n3JdUtm9bGtUxDBeuFeCj3X/jP5uOw1shYWj7MJsewxLledk6P2fi7jkyP9fn7jkyP9dnrxxruz+XKnRqY9GiRZg/f36l9u3bt8Pb29tmx7lSBJSfzvj4eJvtt9wdAugZKsO+dBlmfnMUR48cRscgx8zZsUd+zsbdc2R+rs/dc2R+rs/WORYVFdVqO5cqdMLCwpCenm7Wlp6eDrVaXeVoDgDMmTMHM2fONC3n5eUhIiICAwcOhFqttllsZ9Lz8dZR4yW0AQMGQKFQ2Gzf5QYZBOZsPIGNR1Lxf+c80LZ9W4zo2NDmx6mOVqtFfHy83fJzBu6eI/Nzfe6eI/NzffbKsfyKjLVcqtCJiYnBli1bzNri4+MRExNT7TYqlQoqlapSu0KhsOkH4OFxfV+23rdpvwCWPdgJcrkcGw5ewvPfnUCuxoBJdzex+bFuGoed8nMm7p4j83N97p4j83N9ts6xtvty6GTkgoICHDlyBEeOHAFgvH38yJEjSEkxTridM2cOxo0bZ+r/9NNP4++//8YLL7yA06dP46OPPsI333yDGTNmOCJ8h5DLJCwZHY0JPaMAAAt/OoV5P5yEnm87JyIiqsShhc6BAwfQqVMndOrUCQAwc+ZMdOrUCa+99hoAIDU11VT0AECTJk2wefNmxMfHo0OHDli+fDk+/fRTt7y1/GZkMglzh7XBi4NaAQDi9l3A43H7kVNU6uDIiIiInItDL1317dv3pg/Bq+qpx3379sXhw4ftGFXtCJu91tMykiThmb7NEBnkjZnfHMGeM1cx7IO9+OiRLmgf7n9bYyEiInJWLvUcHZcg3d7DDWnfAN890xMRgV74J6sYo1fuw5q9yTDwUhYRERELHXfQtqE/fpraCwPahKJUb8DCn05h3Gd/4kpOsaNDIyIicigWOm7C31uB1Y91wcIRbeGpkGHvuWuIXbEHX/5xkaM7RERUZ7HQcSOSJOGxmChsntYLnRvXQ75Gh1c2nsADqxLxV2rtnj9ARETkyljouKFm9X3x7dM98dp9beCtlOPgxWwMfe9XvPa/E8gq5J1ZRERUd7DQsRF7vdSztuQyCRPvboIdM/tgSPswGATwf4kX0WfpLny8+zxKtHpHh0hERGR3LHRs7DbfdFWjhvW88NHYLlj3RHe0bqBGfokOi7eeRp+lu/DfxAvQ6FjwEBGR+2KhU0f0bB6Mn569G8se6IBG9byQnqfBq/87iT5LErD2t2QUl7LgISIi98NCpw6RyyT8q0s4fnm+DxaMaIswtSfS8kow/8dT6Ll4J1bEn8G1Ao2jwyQiIrIZFjp1kMpDjnExUdj9Ql+8PrIdIgK9kF2kxbs7z6Ln4l/w/LdHcfxSrqPDJCIiumUu9fZysi2VhxyP9ojEw3dGYNvJNHzyazKO/pODDQcvYcPBS+gQ7o9HujfGfdEN4aPirwoREbke/vWyEWe768oaHnIZ7otuiPuiG+JQSjY+33cBW46n4uilXBy9dBwLfjyFodENMKKD8e4tIiIiV8FCx8ac7a4ra3VuHIDOjQPw6n1tsOHgJXy9/x8kXyvENwcu4ZsDlxCokiNJeRYjO4ejZagfJMnVMyYiInfGQoeqFOyrwtN9muGp3k2x/0I2Nhz8B5uPpyJLo8fHe5Lx8Z5kNA/xxZD2DTC4XRhahbHoISIi58NCh25KkiR0axKIbk0C8eqQllj21XZclodhz9lMnMsowHs7z+K9nWcRGeSNgW1C0b91KLpEBsBDznnuRETkeCx0yGKeCjk6Bwv8Z0gnFOuB+JPp2HoiDXvOXsXFzCJ88msyPvk1Gf5eCvS+oz7uaVkfve+oj2BflaNDJyKiOoqFDtWK2lOB0V3CMbpLOAo1Ouw+cxU7TqXjl6QM5BRp8ePRK/jx6BUAQNuGatzdIhi9mtdH16gAeCrkDo6eiIjqChY6dMt8VB4Y0r4BhrRvAL1B4HBKNnYlZSAh6SpOXskzfa3a/TeUchk6R9ZDj6ZB6NE0CB0j6rHwISIiu2GhYyMCvO8aMD59uWtUILpGBWJ2bCtczddg77mr+PXsNew7l4m0vBL8/ncWfv87C8BZKOUyRIf7484mgegaabzjK8BH6eg0iIjITbDQIbuq76fCqE7hGNUpHEII/H2tEInnM/H735n4IzkLV/M1OHAxGwcuZpu2aVrfB50bB6BjRD10jKiHlmF+UHByMxER1QILHbptJElCs/q+aFbfF4/2iIQQAhcyi7A/OQv7L2Th4MVs/H2tEH9fNX5tOHgJAKDykKFtQzWiw+uhfSN/tA/3R9NgH97ZRURENWKhQw4jSRKaBPugSbAPHrwzAgCQXViKw/9k43BKDo78Y/zKL9HhUEoODqXkmLb1VMjQKkyNtg3VaNNQjdYN1GgV5gdvJX+liYjoOv5VIKcS4KPEva1CcW+rUACAwSCQnFmIY5dycPxSHo5fzsHJK3koKtWbCqFykgREBnqjZZgfWob6oWWYGi3DfBEZ5MNLX0REdRQLHXJqMtn1y12jOhnbyoufU1fycOJKLv5KzcdfqXm4mq/BhcwiXMgsws8n0037UMiNI0ctQvzQPMQXzUOM+2ta34d3fBERuTkWOjbiyi/1dDUVi59hHRqa2q8VaJCUZix6zqTnIym9AOfS81FYqseZ9AKcSS8w248kAQ39vdAsxBdNyy6hRdRTIbME0BsEFLc7MSIisjkWOjbGtz05TrCvCsHNVbirebCpzWAQuJJbjLPpBTibkY9zGQU4l1GA81cLkVusxeWcYlzOKcaeM1cr7MkDi47tQONAb0QF+aBxkDciA73ROMgbjQN9EB7gxZEgIiIXwUKH3JpMJiE8wBvhAd64p1WIqV0IgczC0rI7vAqQfK0Q568WIvlaAS5cK4BWD5y/amyrSpjaExGBXogI8EZ4oDfCA7wQHmBcDvP35JwgIiInwUKH6iRJkowjQL4qdGsSaGrXarX4afMWdOx5Dy7nluJCZiEuZhYiJasIFzOL8E9WEQpL9UjLK0FaXgn2X8iutG+ZBISqPdGonhca1vNCowAvNPT3RMN6Xmjg74WG9Tzh76Xg296JiG4DFjpEN5BJQHiAF5qEGN/RVZEQAlmFpfgnuxgpWcbC51J2MS5lG79fzilGqc6A1NwSpOaWABcrF0IA4KWQo4G/J8LKv9SeaODviVC1cTlU7YlgXxXkMhZDRES3goUOkRUkSUKQrwpBvip0jKhXab0QAlcLNLhcVvRcySnG5exiXMktwZWcYqTmliCrsBTFWr3x4YjXqr40Bhhfp1HfV4UQtQohfp4ILfseolaZtQf5KnmpjIioGix0iGxIkiRjMeLniU6NA6rsU6LVI61sxCc1txhpeSVIzy3BldwSZOQZ268VaKA3CNMlMiD3JscEAryVqO+rQn0/FYJ9lWXfjQVZsK/SdJlOreIIERHVLSx0bI1/R6gGngo5ooJ9EBXsU20fvUHgWoEG6XklSM8zfs/I1yCj/Ht+CTLyNMgsLIXeYLycllVYiqT0/BqP7y2X492zexHkq0Kgj9JYDPkoEeCjNC77lLcrUc9bAZUH7zAjItfFQofICcllEkLVxrk6N2MwCGQVleJqvgbXCjTIyDN+N36V4lqBpmxdKbKLjEVRkV7C39eK8Pe1Ioti8VV5IMBHgUBvJep5G4uhet5lyz5KBHgrEOBtbCv/7qWQc7I1ETkFpyh0PvzwQyxduhRpaWno0KED3n//fXTr1q3KvnFxcXj88cfN2lQqFUpKSm5HqERORSa7fvdYTQwGgat5Rdi0dQfadumBnBI9sgtLcbWgFNllI0KZhRpkF2qN34u00BsECjQ6FGh0+Cer2OK4lB4y1PNSoJ63AvW8lPD3VpiW/b0U8PdWGr97GdvVZT+rPT34slYisimHFzpff/01Zs6ciY8//hjdu3fHO++8g9jYWCQlJSEkJKTKbdRqNZKSkkzL/D9HoprJZBICfZQI8wa6NwmEQnHzZz8LIZBXrCsrekqRVahFdqFxZCi76PrPOUVa5BQb1+cWl0KrFyjVGcousWmsjtNX5QF/LwX8PI3f1V4KqD0VUHt5lH03FkR+FdvKflbJ+IhyIjLn8ELn7bffxuTJk02jNB9//DE2b96Mzz77DC+99FKV20iShLCwsNsZJlGdI0kS/L0V8Pe2/GUYQggUluqRW2wshHKLtcguMn7PKdIit1iL3LLvOcWlyC3WIbeoFHklxlEjAKYRpNpSyuR488Ru+JUVS36eZd9VHqZlX5UHfD09oPb0gK9KAV9PD/iWrfdVecBbyUtvRO7CoYVOaWkpDh48iDlz5pjaZDIZ+vfvj8TExGq3KygoQGRkJAwGAzp37ow333wTbdu2rbKvRqOBRnP9/yrz8vIAGB8Mp9VqbZQJoNNd/4fZlvt1JuV5uWt+gPvneDvyU8mAEB8PhPhY98+LVm9AfokOucVa4/cSLfKKdcgr+17ell+iQ37Z97wSXdl3LUq0BgBAqUFCer4G6bUYTSonkwBvpQd8VXL4qjzgo/Io+y43/qy83u6jksNHeX2dt1IO3xuWbXn7P39HXZu75wfYL8fa7k8SwnGvo7xy5QoaNWqEffv2ISYmxtT+wgsvYPfu3fjjjz8qbZOYmIizZ88iOjoaubm5WLZsGfbs2YOTJ08iPDy8Uv958+Zh/vz5ldrXrVsHb29vm+XyTwGw7LgH/JUCC7robbZfIrKM3gAU64FiHVCiB0r0Eor1QInO2F6iB0p00vWfy/qU6CouA8IOt056SAIqOaCSA0oZ4CkHlHIBlQymdpWsrK2sT6V2GaCssE4hMxZkRHVFUVERHnnkEeTm5kKtVlu8ncMvXVkrJibGrCjq2bMnWrdujVWrVmHhwoWV+s+ZMwczZ840Lefl5SEiIgIDBw606kTV5MTlPCw7/jskAAMGDKhx/oMr0mq1iI+Pd9v8APfPkfndnBACJVoD8jU6FJToUFhqvIxWqNGXfdehQKM3fi81fi/U6FBYqkdRqR4FJToUlRqXCzQ6aPXG/4/UCQk6HVBodkXu1qsUL4UMXko5vBVy43elcQTJUyGDt8IDXkq5ab2nQla2Tg5vpRxeZduU96243kshh8pDBpkDKin+jro+e+VYfkXGWg4tdIKDgyGXy5Genm7Wnp6ebvEcHIVCgU6dOuHcuXNVrlepVFCpKt+RolAobPoBeHhcP5W23rezcff8APfPkflVT6kE1NU/4sgqpToDisqKpaKy4qdIoy8rhowFVHF5e6mxT3nhVFyqR2GpDsVlRVRReX/t9RHjYq0BxVoDsmCfyyCeCpmxIFLI4am8XiB5VvjyKuvjqZTD06OsePKQGdcpK/St2OYhh6dSVtYuh0IuVZoTxd9R12frHGu7L4cWOkqlEl26dMHOnTsxcuRIAIDBYMDOnTsxdepUi/ah1+tx/PhxDBkyxI6REhFZT+khg9LD+PwhW9FoSvG/zVvR+55+0AoZCssKpIoFUfnPxdryZQOKtdf7Gdv1KNHqzfoWa/Uo1RlMxyrRGlCiNSDbToVUOZkEU0GklEswlMqxMjkRXkrjyFJ5QeSpMP5c3qYqG6lSeVz/blpX4buqij4qDxkfZVBHOPzS1cyZMzF+/Hh07doV3bp1wzvvvIPCwkLTXVjjxo1Do0aNsGjRIgDAggUL0KNHDzRv3hw5OTlYunQpLl68iCeeeMKRaRAR3RYymQSVHAjyVdllREBvECjWXi+Cisu+l2iv/2xcbzD1K7mhvUSnR0mF4qlEa4Cm7GeNzmDcn06P8hmiBoGyIq18tEpCRlrNT/m+VR4yqawQMhY/yrICyFQgechNbeXLxqKpvO/19TcuV2yruCwJAwq0xrsLfaSqR7PIthxe6Dz00EO4evUqXnvtNaSlpaFjx47Ytm0bQkNDAQApKSmQya5X3dnZ2Zg8eTLS0tIQEBCALl26YN++fWjTpo2jUiAichtymWS8/V5l3z8PQghodAbjV4UCqaBYg4Rff0PHrt2gM0go0RlQotWb+mh0xmKpvPDSaMv2oSvbR1kxdX2/epTqDdCU7b983hQA6AwCulI9Cktv9w0kHnjlwC8AjO+qU8grFEdyY+GllMug8JCglJsXUUoPGVRlbUoPGRTlP8tlZkWXUl5hXYX1N/a/3i5BUb4sd8z8LHtxeKEDAFOnTq32UlVCQoLZ8ooVK7BixYrbEJV1BPigMiIiS0mSZLpcBa/rI1NarSf+UQO9mgfbZcTKYBCmwqi8YNLoDCitUCxpdMYCqmKBVFpePJUVUOU/l1bYl3G54v6M3yv2KdUZoDNc/3shBEx97D+GZTkPmVSpMFLIJdNyVe2KsiJMLgOKr0pwlgklTlHoEBER3Q4ymWS6G80RtFotftq8Bf0HxsIgyaEpK6JKdcbCqnKBVLFdD22F5VKdAZoKP2v15vsp1QuUlu9fX95HmPcp265i8QVcH+0CajfaFeXrPPOfWOgQERHdRuWTr40jVs5x55XBIIzFj/568aPVGdu0FdoqFkzaisWSwWAqwkpKdUhNTqr5oLcJCx0iIqI6TiaT4Ckru5R4i7RaLbYUnrZBVLbhPGNLRERERDbGQoeIiIjcFgsdIiIiclssdGzEca9GJSIiouqw0LEx93nEEhERketjoUNERERui4UOERERuS0WOkREROS2WOgQERGR22KhYyO86YqIiMj5sNCxMYm3XRERETkNFjpERETktljoEBERkdtioUNERERui4WOjZTqDI4OgYiIiG7AQsdGzl8tcHQIREREdAMWOjbSKswPngoZOgXxRnMiIiJnwULHRjo1DsDx1/pjeCQvYRERETkLFjpERETktljoEBERkdtioUNERERui4UOERERuS0WOkREROS2WOgQERGR22KhQ0RERG6LhQ4RERG5LRY6RERE5LZY6BAREZHbYqFDREREbouFDhEREbktFjpERETktljoEBERkdvycHQAt5sQAgCQl5dn831rtVoUFRUhLy8PCoXC5vt3NHfPD3D/HJmf63P3HJmf67NXjuV/t8v/jluqzhU6+fn5AICIiAgHR0JERETWys/Ph7+/v8X9JWFtaeTiDAYDrly5Aj8/P0iSZNN95+XlISIiAv/88w/UarVN9+0M3D0/wP1zZH6uz91zZH6uz145CiGQn5+Phg0bQiazfOZNnRvRkclkCA8Pt+sx1Gq12/4CA+6fH+D+OTI/1+fuOTI/12ePHK0ZySnHychERETktljoEBERkdtioWNDKpUKc+fOhUqlcnQoduHu+QHunyPzc33uniPzc33OlmOdm4xMREREdQdHdIiIiMhtsdAhIiIit8VCh4iIiNwWCx0iIiJyWyx0bOTDDz9EVFQUPD090b17d/z555+ODgmLFi3CnXfeCT8/P4SEhGDkyJFISkoy69O3b19IkmT29fTTT5v1SUlJwdChQ+Ht7Y2QkBDMnj0bOp3OrE9CQgI6d+4MlUqF5s2bIy4urlI89jhH8+bNqxR/q1atTOtLSkowZcoUBAUFwdfXF6NHj0Z6errL5BcVFVUpP0mSMGXKFACu+fnt2bMHw4YNQ8OGDSFJEjZt2mS2XgiB1157DQ0aNICXlxf69++Ps2fPmvXJysrC2LFjoVarUa9ePUyaNAkFBQVmfY4dO4ZevXrB09MTERERWLJkSaVYvv32W7Rq1Qqenp5o3749tmzZYnUs1uSn1Wrx4osvon379vDx8UHDhg0xbtw4XLlyxWwfVX3uixcvdvr8AGDChAmVYh80aJBZH2f+/CzJsar/JiVJwtKlS019nPUztOTvgjP9u2lJLDUSdMvWr18vlEql+Oyzz8TJkyfF5MmTRb169UR6erpD44qNjRVr164VJ06cEEeOHBFDhgwRjRs3FgUFBaY+ffr0EZMnTxapqammr9zcXNN6nU4n2rVrJ/r37y8OHz4stmzZIoKDg8WcOXNMff7++2/h7e0tZs6cKU6dOiXef/99IZfLxbZt20x97HWO5s6dK9q2bWsW/9WrV03rn376aRERESF27twpDhw4IHr06CF69uzpMvllZGSY5RYfHy8AiF27dgkhXPPz27Jli3jllVfE999/LwCIjRs3mq1fvHix8Pf3F5s2bRJHjx4Vw4cPF02aNBHFxcWmPoMGDRIdOnQQv//+u/j1119F8+bNxZgxY0zrc3NzRWhoqBg7dqw4ceKE+Oqrr4SXl5dYtWqVqc9vv/0m5HK5WLJkiTh16pT4z3/+IxQKhTh+/LhVsViTX05Ojujfv7/4+uuvxenTp0ViYqLo1q2b6NKli9k+IiMjxYIFC8w+14r/3TprfkIIMX78eDFo0CCz2LOyssz6OPPnZ0mOFXNLTU0Vn332mZAkSZw/f97Ux1k/Q0v+LjjTv5s1xWIJFjo20K1bNzFlyhTTsl6vFw0bNhSLFi1yYFSVZWRkCABi9+7dprY+ffqI6dOnV7vNli1bhEwmE2lpaaa2lStXCrVaLTQajRBCiBdeeEG0bdvWbLuHHnpIxMbGmpbtdY7mzp0rOnToUOW6nJwcoVAoxLfffmtq++uvvwQAkZiY6BL53Wj69OmiWbNmwmAwCCFc//O78Y+IwWAQYWFhYunSpaa2nJwcoVKpxFdffSWEEOLUqVMCgNi/f7+pz9atW4UkSeLy5ctCCCE++ugjERAQYMpRCCFefPFF0bJlS9Pygw8+KIYOHWoWT/fu3cVTTz1lcSzW5leVP//8UwAQFy9eNLVFRkaKFStWVLuNM+c3fvx4MWLEiGq3caXPr7ocbzRixAhx7733mrW5ymd4498FZ/p305JYLMFLV7eotLQUBw8eRP/+/U1tMpkM/fv3R2JiogMjqyw3NxcAEBgYaNb+5ZdfIjg4GO3atcOcOXNQVFRkWpeYmIj27dsjNDTU1BYbG4u8vDycPHnS1Kdi/uV9yvO39zk6e/YsGjZsiKZNm2Ls2LFISUkBABw8eBBardbsuK1atULjxo1Nx3WF/MqVlpbiiy++wMSJE81eSOvqn19FycnJSEtLMzuWv78/unfvbvaZ1atXD127djX16d+/P2QyGf744w9Tn969e0OpVJrllJSUhOzsbIvytiQWW8jNzYUkSahXr55Z++LFixEUFIROnTph6dKlZpcFnD2/hIQEhISEoGXLlnjmmWeQmZlpFrs7fX7p6enYvHkzJk2aVGmdK3yGN/5dcKZ/Ny2JxRJ17qWetnbt2jXo9XqzDxwAQkNDcfr0aQdFVZnBYMBzzz2Hu+66C+3atTO1P/LII4iMjETDhg1x7NgxvPjii0hKSsL3338PAEhLS6syt/J1N+uTl5eH4uJiZGdn2+0cde/eHXFxcWjZsiVSU1Mxf/589OrVCydOnEBaWhqUSmWlPyChoaE1xu4s+VW0adMm5OTkYMKECaY2V//8blQeU1XHqhhvSEiI2XoPDw8EBgaa9WnSpEmlfZSvCwgIqDbvivuoKZZbVVJSghdffBFjxowxe/nhtGnT0LlzZwQGBmLfvn2YM2cOUlNT8fbbbzt9foMGDcL999+PJk2a4Pz583j55ZcxePBgJCYmQi6Xu9XnBwCff/45/Pz8cP/995u1u8JnWNXfBWf6d9OSWCzBQqeOmDJlCk6cOIG9e/eatT/55JOmn9u3b48GDRqgX79+OH/+PJo1a3a7w7Ta4MGDTT9HR0eje/fuiIyMxDfffAMvLy8HRmZ7a9asweDBg9GwYUNTm6t/fnWZVqvFgw8+CCEEVq5cabZu5syZpp+jo6OhVCrx1FNPYdGiRU7zWP3qPPzww6af27dvj+joaDRr1gwJCQno16+fAyOzj88++wxjx46Fp6enWbsrfIbV/V1wN7x0dYuCg4Mhl8srzQJPT09HWFiYg6IyN3XqVPz000/YtWsXwsPDb9q3e/fuAIBz584BAMLCwqrMrXzdzfqo1Wp4eXnd1nNUr1493HHHHTh37hzCwsJQWlqKnJycao/rKvldvHgRO3bswBNPPHHTfq7++ZXv72bHCgsLQ0ZGhtl6nU6HrKwsm3yuFdfXFEttlRc5Fy9eRHx8vNloTlW6d+8OnU6HCxcu3DT2inE7Mr+KmjZtiuDgYLPfSVf//Mr9+uuvSEpKqvG/S8D5PsPq/i4407+blsRiCRY6t0ipVKJLly7YuXOnqc1gMGDnzp2IiYlxYGTG2w6nTp2KjRs34pdffqk0TFqVI0eOAAAaNGgAAIiJicHx48fN/mEq/4e5TZs2pj4V8y/vU57/7TxHBQUFOH/+PBo0aIAuXbpAoVCYHTcpKQkpKSmm47pKfmvXrkVISAiGDh16036u/vk1adIEYWFhZsfKy8vDH3/8YfaZ5eTk4ODBg6Y+v/zyCwwGg6nQi4mJwZ49e6DVas1yatmyJQICAizK25JYaqO8yDl79ix27NiBoKCgGrc5cuQIZDKZ6ZKPM+d3o0uXLiEzM9Psd9KVP7+K1qxZgy5duqBDhw419nWWz7CmvwvO9O+mJbFYxOJpy1St9evXC5VKJeLi4sSpU6fEk08+KerVq2c2I90RnnnmGeHv7y8SEhLMbnEsKioSQghx7tw5sWDBAnHgwAGRnJws/ve//4mmTZuK3r17m/ZRfhvhwIEDxZEjR8S2bdtE/fr1q7yNcPbs2eKvv/4SH374YZW3EdrjHM2aNUskJCSI5ORk8dtvv4n+/fuL4OBgkZGRIYQw3prYuHFj8csvv4gDBw6ImJgYERMT4zL5CWG8E6Fx48bixRdfNGt31c8vPz9fHD58WBw+fFgAEG+//bY4fPiw6a6jxYsXi3r16on//e9/4tixY2LEiBFV3l7eqVMn8ccff4i9e/eKFi1amN2enJOTI0JDQ8Vjjz0mTpw4IdavXy+8vb0r3brr4eEhli1bJv766y8xd+7cKm/drSkWa/IrLS0Vw4cPF+Hh4eLIkSNm/12W362yb98+sWLFCnHkyBFx/vx58cUXX4j69euLcePGOX1++fn54vnnnxeJiYkiOTlZ7NixQ3Tu3Fm0aNFClJSUuMTnV1OO5XJzc4W3t7dYuXJlpe2d+TOs6e+CEM7172ZNsViChY6NvP/++6Jx48ZCqVSKbt26id9//93RIQkAVX6tXbtWCCFESkqK6N27twgMDBQqlUo0b95czJ492+w5LEIIceHCBTF48GDh5eUlgoODxaxZs4RWqzXrs2vXLtGxY0ehVCpF06ZNTceoyB7n6KGHHhINGjQQSqVSNGrUSDz00EPi3LlzpvXFxcXi3//+twgICBDe3t5i1KhRIjU11WXyE0KIn3/+WQAQSUlJZu2u+vnt2rWryt/L8ePHCyGMt8y++uqrIjQ0VKhUKtGvX79KuWdmZooxY8YIX19foVarxeOPPy7y8/PN+hw9elTcfffdQqVSiUaNGonFixdXiuWbb74Rd9xxh1AqlaJt27Zi8+bNZusticWa/JKTk6v977L82UgHDx4U3bt3F/7+/sLT01O0bt1avPnmm2aFgrPmV1RUJAYOHCjq168vFAqFiIyMFJMnT65UEDvz51dTjuVWrVolvLy8RE5OTqXtnfkzrOnvghDO9e+mJbHURCpLnIiIiMjtcI4OERERuS0WOkREROS2WOgQERGR22KhQ0RERG6LhQ4RERG5LRY6RERE5LZY6BAREZHbYqFD5ETi4uIqvanXmSUkJECSpErvorGnzMxMhISEmN4ZREZRUVF45513HB1GrZw6dQrh4eEoLCx0dCjkhljoEN1gwoQJkCTJ9BUUFIRBgwbh2LFjVu1n3rx56Nixo32CrMPeeOMNjBgxAlFRUTX2vXDhAiRJMr0DjGxr3rx5SEhIqLFf3759zf6bkiQJTz/9tGl9mzZt0KNHD7z99tt2jJbqKhY6RFUYNGgQUlNTkZqaip07d8LDwwP33Xefo8OqM0pLS6tsLyoqwpo1azBp0qTbHFHdVNXnoNVqsXz5crOXUWZkZGDVqlU33dfkyZNN/02lpqZiyZIlZusff/xxrFy5EjqdzjbBE5VhoUNUBZVKhbCwMISFhaFjx4546aWX8M8//+Dq1aumPi+++CLuuOMOeHt7o2nTpnj11VdN//jHxcVh/vz5OHr0qOn/YOPi4gAAOTk5eOqppxAaGgpPT0+0a9cOP/30k9nxf/75Z7Ru3Rq+vr6moqs65ZePdu7cia5du8Lb2xs9e/ZEUlKSqc+ECRMwcuRIs+2ee+459O3b17Tct29fPPvss3juuecQEBCA0NBQfPLJJygsLMTjjz8OPz8/NG/eHFu3bq0Uw2+//Ybo6Gh4enqiR48eOHHihNn6vXv3olevXvDy8kJERASmTZtmdpkiKioKCxcuxLhx46BWq/Hkk09WmeuWLVugUqnQo0cPU1t2djbGjh2L+vXrw8vLCy1atMDatWsBwPRm5k6dOkGSJLN8P/30U7Ru3Rqenp5o1aoVPvroI9O68pGg9evXo2fPnqbPaffu3dV8CtfzePPNNzFx4kT4+fmhcePGWL16tWl9VZf6jhw5AkmSTJfiyi9f/vTTT2jZsiW8vb3xr3/9C0VFRfj8888RFRWFgIAATJs2DXq93uz4+fn5GDNmDHx8fNCoUSN8+OGHZutzcnLwxBNPoH79+lCr1bj33ntx9OhR0/ryUchPP/0UTZo0gaenZ6UcJUkCANx77704efIkNm7ciGHDhiE8PPym58bb29v031RYWBjUarXZ+gEDBiArK6vGc0xkNavejEVUB4wfP16MGDHCtJyfny+eeuop0bx5c6HX603tCxcuFL/99ptITk4WP/zwgwgNDRVvvfWWEEKIoqIiMWvWLNG2bVuztwPr9XrRo0cP0bZtW7F9+3Zx/vx58eOPP4otW7YIIYRYu3atUCgUon///mL//v3i4MGDonXr1uKRRx6pNt7yFxB2795dJCQkiJMnT4pevXqJnj17VpuTEEJMnz5d9OnTx7Tcp08f4efnJxYuXCjOnDkjFi5cKORyuRg8eLBYvXq1OHPmjHjmmWdEUFCQKCwsNDt269atxfbt28WxY8fEfffdJ6KiokRpaakQwviWdR8fH7FixQpx5swZ8dtvv4lOnTqJCRMmmI4dGRkp1Gq1WLZsmTh37pzZi1krmjZtmhg0aJBZ25QpU0THjh3F/v37RXJysoiPjxc//PCDEEKIP//8UwAQO3bsEKmpqSIzM1MIIcQXX3whGjRoIL777jvx999/i++++04EBgaKuLg4IYQwvXwzPDxcbNiwQZw6dUo88cQTws/PT1y7dq3azyIyMlIEBgaKDz/8UJw9e1YsWrRIyGQycfr0abPzlZ2dbdqm/A3ZycnJQojrvwMDBgwQhw4dErt37xZBQUFi4MCB4sEHHxQnT54UP/74o1AqlWL9+vVmx/bz8xOLFi0SSUlJ4r333hNyuVxs377d1Kd///5i2LBhYv/+/eLMmTNi1qxZIigoyHRe5s6dK3x8fMSgQYPEoUOHxNGjR6vN9dChQ8Lb21u0atWqyhdbVtSnTx8RHBwsgoKCRNu2bcVLL71k+h2qqHv37mLu3Lk33ReRtVjoEN1g/PjxQi6XCx8fH+Hj4yMAiAYNGoiDBw/edLulS5eKLl26mJbnzp0rOnToYNbn559/FjKZrNq3C69du1YAMPtD/+GHH4rQ0NBqj1v+x3PHjh2mts2bNwsAori42JSTJYXO3XffbVrW6XTCx8dHPPbYY6a21NRUAUAkJiaaHbviH9zMzEzh5eUlvv76ayGEEJMmTRJPPvmk2bF//fVXIZPJTPFFRkaKkSNHVptjuREjRoiJEyeatQ0bNkw8/vjjVfYvL1gOHz5s1t6sWTOxbt06s7aFCxeKmJgYs+0qvk1aq9WK8PBwUzFblcjISPHoo4+alg0GgwgJCRErV64UQlhe6Nz4O/DUU08Jb29vszd8x8bGiqeeesrs2DcWgQ899JAYPHiwEMJ4ztVqdaU3aDdr1kysWrVKCGH8nVUoFCIjI6PaHHU6nXjnnXfE3XffLf71r3+JadOmiR49eoitW7dWu82qVavEtm3bxLFjx8QXX3whGjVqJEaNGlWp36hRo8wKYCJb8LjtQ0hELuCee+7BypUrARgvjXz00UcYPHgw/vzzT0RGRgIAvv76a7z33ns4f/48CgoKoNPpKg3H3+jIkSMIDw/HHXfcUW0fb29vNGvWzLTcoEEDZGRk1BhzdHS02TaAce5E48aNa9y2qn3I5XIEBQWhffv2prbQ0FDTfiuKiYkx/RwYGIiWLVvir7/+AgAcPXoUx44dw5dffmnqI4SAwWBAcnIyWrduDQDo2rVrjfEVFxdXupzyzDPPYPTo0Th06BAGDhyIkSNHomfPntXuo7CwEOfPn8ekSZMwefJkU7tOp4O/v3+1eXl4eKBr166mvKpT8RxKkoSwsDCLPr+KbvwdCA0NRVRUFHx9fc3abvY5lC+X34l19OhRFBQUICgoyKxPcXExzp8/b1qOjIxE/fr1q43NYDBAq9Vi586dePPNN9G3b1+8/PLL2LhxY7XbVLwU2b59ezRo0AD9+vXD+fPnzfL08vJCUVFRtfshqg0WOkRV8PHxQfPmzU3Ln376Kfz9/fHJJ5/g9ddfR2JiIsaOHYv58+cjNjYW/v7+WL9+PZYvX37T/Xp5edV4bIVCYbYsSRKEEFZtVz6PwmAwAABkMlmlfVScTHqzY99sv5YoKCjAU089hWnTplVaV7EI8/HxqXFfwcHByM7ONmsbPHgwLl68iC1btiA+Ph79+vXDlClTsGzZsmrjAYBPPvkE3bt3N1snl8trjKEmVZ3Dip8DALPPojafw437tURBQQEaNGhQ5V1SFR9pUNPnoFAo8Pzzz5u1hYaGmt1FVZPy837u3DmzQicrK8tsmcgWWOgQWUCSJMhkMhQXFwMA9u3bh8jISLzyyiumPhcvXjTbRqlUVposGh0djUuXLuHMmTM3HdWxtfr161eaIHzkyJFKfzxr6/fffzcVLdnZ2Thz5oxppKZz5844deqUWeFYW506dcIXX3xRqb1+/foYP348xo8fj169emH27NlYtmwZlEolAJh9DqGhoWjYsCH+/vtvjB07tsa8evfuDcA44nPw4EFMnTq11vGXj5SkpqYiICAAAGx66/vvv/9eabni55CWlgYPDw+Lbs23xLx582q1XXnO5SOP5U6cOIF//etftxgVkTkWOkRV0Gg0SEtLA2D8w/3BBx+goKAAw4YNAwC0aNECKSkpWL9+Pe68805s3ry50tB9VFQUkpOTTZer/Pz80KdPH/Tu3RujR4/G22+/jebNm+P06dOQJAmDBg2yWz733nsvli5div/7v/9DTEwMvvjiC5w4cQKdOnWyyf4XLFiAoKAghIaG4pVXXkFwcLDpLq8XX3wRPXr0wNSpU/HEE0/Ax8cHp06dQnx8PD744AOrjhMbG4s5c+YgOzvbVCi89tpr6NKlC9q2bQuNRoOffvrJ9Mc9JCQEXl5e2LZtG8LDw+Hp6Ql/f3/Mnz8f06ZNg7+/PwYNGgSNRoMDBw4gOzsbM2fONB3vww8/RIsWLdC6dWusWLEC2dnZmDhxYq3PU/PmzREREYF58+bhjTfewJkzZ2ocBbTGb7/9hiVLlmDkyJGIj4/Ht99+i82bNwMA+vfvj5iYGIwcORJLlizBHXfcgStXrmDz5s0YNWqURZcOa+P8+fNYt24dhgwZgqCgIBw7dgwzZsxA7969zS7zXbhwAZcvX0b//v3tEgfVXby9nKgK27ZtQ4MGDdCgQQN0794d+/fvx7fffmu6PXn48OGYMWMGpk6dio4dO2Lfvn149dVXzfYxevRoDBo0CPfccw/q16+Pr776CgDw3Xff4c4778SYMWPQpk0bvPDCC5VGfmwtNjYWr776Kl544QXceeedyM/Px7hx42y2/8WLF2P69Ono0qUL0tLS8OOPP5pGU6Kjo7F7926cOXMGvXr1QqdOnfDaa6+hYcOGVh+nffv26Ny5M7755htTm1KpxJw5cxAdHY3evXtDLpdj/fr1AIzzat577z2sWrUKDRs2xIgRIwAATzzxBD799FOsXbsW7du3R58+fRAXF2e6Hb1iXosXL0aHDh2wd+9e/PDDDwgODq7taYJCocBXX32F06dPIzo6Gm+99RZef/31Wu/vRrNmzcKBAwfQqVMnvP7663j77bcRGxsLwDgquWXLFvTu3RuPP/447rjjDjz88MO4ePGiae6VPSiVSuzYsQMDBw5Eq1atMGvWLIwePRo//vijWb+vvvoKAwcONM2BI7IVSVhy8Z+IyEls3rwZs2fPxokTJ0xzXmztwoULaNKkCQ4fPsynW98GpaWlaNGiBdatW4e77rrL0eGQm+GlKyJyKUOHDsXZs2dx+fJlREREODocsoGUlBS8/PLLLHLILjiiQ0R0A47oELkPFjpERETktjgZmYiIiNwWCx0iIiJyWyx0iIiIyG2x0CEiIiK3xUKHiIiI3BYLHSIiInJbLHSIiIjIbbHQISIiIrfFQoeIiIjc1v8DsHM4y5TzoiMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [i for i in range(40000*5)]\n",
    "y = [lr_lambda(i//5) for i in x]\n",
    "plt.plot(x, y)\n",
    "plt.xlabel(f'Batch number (step number * {gradient_accumulation_steps})')\n",
    "plt.ylabel('Learning rate multiplier')\n",
    "plt.title('Learning rate decay')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "transformer = transformer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "# we don't use label smoothing yet. migh implement later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kek' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t4/jszkcmcn7lvgmswvxnpyh1x00000gn/T/ipykernel_27725/3802465820.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkek\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'kek' is not defined"
     ]
    }
   ],
   "source": [
    "# kek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "losses = []\n",
    "grad_norms = {n: [] for n, p in transformer.named_parameters() if p.requires_grad}\n",
    "batch_indices = []\n",
    "plt.ion()\n",
    "\n",
    "# Utility\n",
    "count = 0\n",
    "optimizer.zero_grad()\n",
    "n_epochs = 5\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(f\"Epoch {epoch}/{n_epochs}\")\n",
    "    for batch_data, batch_labels in tqdm(dataloader):\n",
    "        count += 1\n",
    "        batch_data = batch_data.squeeze(1).to(device)  # Remove the extra dimension\n",
    "        batch_labels = batch_labels.squeeze(1).to(device)  # Remove the extra dimension\n",
    "\n",
    "        output = transformer(batch_data, batch_labels, causal_mask=True)\n",
    "\n",
    "        loss = cel(output.permute(0, 2, 1)[:, :, :-1], batch_labels[:, 1:]) / gradient_accumulation_steps\n",
    "        loss.backward()\n",
    "\n",
    "        if count % gradient_accumulation_steps == 0:\n",
    "            latest_grad_norms = {}  # Store the latest gradient norms for bar plot\n",
    "            for name, param in transformer.named_parameters():\n",
    "                if param.grad is not None:\n",
    "                    grad_norm = param.grad.norm(2).item()\n",
    "                    grad_norms[name].append(grad_norm)\n",
    "                    latest_grad_norms[name] = grad_norm  # Store the latest gradient norm\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(transformer.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        batch_indices.append(count)\n",
    "\n",
    "        # Update the plots every 100 batches or at the end of an epoch\n",
    "        if (count % 100 == 0) or (count % len(dataloader) == 0):\n",
    "            clear_output(wait=True)\n",
    "            fig, ax = plt.subplots(nrows=3, ncols=1, figsize=(10, 12))\n",
    "\n",
    "            # Plot training loss\n",
    "            ax[0].plot(batch_indices, losses, label='Training Loss')\n",
    "            ax[0].set_xlabel('Batch')\n",
    "            ax[0].set_ylabel('Loss')\n",
    "            ax[0].set_title('Training Loss')\n",
    "            ax[0].legend()\n",
    "            ax[0].grid(True)\n",
    "\n",
    "            # Plot gradient magnitudes (Top 5)\n",
    "            grad_norms_df = pd.DataFrame(grad_norms)\n",
    "            grad_norms_df.index = (grad_norms_df.index + 1) * gradient_accumulation_steps\n",
    "            grad_norms_df[grad_norms_df.iloc[-1].nlargest(5).index].plot(ax=ax[1])\n",
    "            ax[1].set_xlabel('Batch')\n",
    "            ax[1].set_ylabel('Gradient Norm (L2)')\n",
    "            ax[1].set_title('Gradient Magnitudes (Top 5)')\n",
    "            ax[1].grid(True)\n",
    "\n",
    "            # Bar plot of all latest gradient norms\n",
    "            names, norms = zip(*latest_grad_norms.items())\n",
    "            ax[2].bar(names, norms)\n",
    "            ax[2].set_xticks(range(len(names)))\n",
    "            ax[2].set_xticklabels(names, rotation=90)\n",
    "            ax[2].set_ylabel('Gradient Norm (L2)')\n",
    "            ax[2].set_title('Latest Gradient Magnitudes (All)')\n",
    "            ax[2].grid(True)\n",
    "\n",
    "            # Save plots at the end of an epoch\n",
    "            if count % len(dataloader) == 0:\n",
    "                plt.savefig(f\"training_and_grad_norms_v{version}_epoch_{epoch}.png\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    torch.save(transformer.state_dict(), f\"transformer_v{version}_epoch_{epoch}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.load_state_dict(torch.load(\"transformer_epoch_3_v7.pth\", map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inference baby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, model, tokenizer, device, max_len=max_len):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Tokenize input sentence and convert to tensor\n",
    "        # input_ids = tokenizer.encode(sentence, return_tensors=\"pt\").to(device)\n",
    "        input_ids = tokenizer(sentence, return_tensors='pt', padding='max_length', max_length=max_len, truncation=True)['input_ids']\n",
    "\n",
    "        # Create attention mask (1 for non-pad tokens)\n",
    "        encoder_padding_mask = create_padding_mask(input_ids, pad_token_id=0)\n",
    "\n",
    "        # Pass through encoder\n",
    "        input_ids = model.embedding(input_ids)\n",
    "        encoder_outputs = model.encoder(input_ids, padding_mask=encoder_padding_mask)\n",
    "\n",
    "        # Initialize decoder input with BOS token\n",
    "        # decoder_input = torch.tensor([[tokenizer.bos_token_id]], device=device)\n",
    "        decoder_input = torch.tensor([[tokenizer.cls_token_id]], device=device)\n",
    "\n",
    "        translated_tokens = []\n",
    "\n",
    "        for i in range(max_len):\n",
    "            # Create causal mask and decoder attention mask if needed\n",
    "            decoder_padding_mask = create_padding_mask(decoder_input)\n",
    "            decoder_input_embedded = model.embedding(decoder_input)\n",
    "            filler = torch.zeros(encoder_outputs.size(0), encoder_outputs.size(1) - decoder_input_embedded.size(1), encoder_outputs.size(2))\n",
    "            decoder_input_embedded = torch.cat([decoder_input_embedded, filler], dim=1)\n",
    "            filler = torch.zeros(decoder_padding_mask.size(0), encoder_padding_mask.size(1) - decoder_padding_mask.size(1))\n",
    "            decoder_padding_mask = torch.cat([decoder_padding_mask, filler], dim=1)\n",
    "            # decoder_input_embedded = decoder_input_embedded.expand(encoder_outputs.size())\n",
    "\n",
    "            # Forward pass through model\n",
    "            outputs = model.decoder(\n",
    "                decoder_input_embedded,\n",
    "                encoder_outputs,\n",
    "                causal_mask=True,\n",
    "                # causal_mask=False,\n",
    "                decoder_padding_mask=decoder_padding_mask,\n",
    "                encoder_padding_mask=encoder_padding_mask\n",
    "            )\n",
    "\n",
    "            next_token_logits = outputs[:, i, :]  # (1, vocab_size)\n",
    "\n",
    "            # Pick token with highest probability\n",
    "            next_token_id = torch.argmax(next_token_logits, dim=-1).item()\n",
    "\n",
    "            # Append predicted token\n",
    "            translated_tokens.append(next_token_id)\n",
    "\n",
    "\n",
    "            # Update decoder input\n",
    "            decoder_input = torch.cat(\n",
    "                [decoder_input, torch.tensor([[next_token_id]], device=device)], dim=1\n",
    "            )\n",
    "\n",
    "            # Break if EOS\n",
    "            # if next_token_id == tokenizer.eos_token_id:\n",
    "            if next_token_id == tokenizer.sep_token_id:\n",
    "                break\n",
    "\n",
    "        # Decode tokens into sentence\n",
    "        translated_sentence = tokenizer.decode(translated_tokens, skip_special_tokens=True)\n",
    "        return translated_sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence_beam_search(sentence, model, tokenizer, device, max_len=max_len, beam_width=3, length_penalty=0.6):\n",
    "    # length_penalty = 0 makes it equivalent to normal beam search\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Tokenize input sentence and convert to tensor\n",
    "        # input_ids = tokenizer.encode(sentence, return_tensors=\"pt\").to(device)\n",
    "        input_ids = tokenizer(sentence, return_tensors='pt', padding='max_length', max_length=max_len, truncation=True)['input_ids']\n",
    "\n",
    "        # Create attention mask (1 for non-pad tokens)\n",
    "        encoder_padding_mask = create_padding_mask(input_ids, pad_token_id=0)\n",
    "\n",
    "        # Pass through encoder\n",
    "        input_ids = model.embedding(input_ids)\n",
    "        encoder_outputs = model.encoder(input_ids, padding_mask=encoder_padding_mask)\n",
    "\n",
    "        # Initialize decoder input with BOS token\n",
    "        # decoder_input = torch.tensor([[tokenizer.bos_token_id]], device=device)\n",
    "        decoder_input = torch.tensor([[tokenizer.cls_token_id]], device=device)\n",
    "\n",
    "        # translated_tokens = []\n",
    "        # Beam search variables\n",
    "        hypotheses = [(decoder_input, 0)]  # List of (current_sequence, cumulative_log_prob)\n",
    "        completed_hypotheses = []\n",
    "\n",
    "        for i in range(max_len):\n",
    "            all_candidates = []\n",
    "            for seq, cumulative_log_prob in hypotheses:\n",
    "                # Create causal mask and decoder attention mask if needed\n",
    "                decoder_padding_mask = create_padding_mask(seq)\n",
    "                decoder_input_embedded = model.embedding(seq)\n",
    "                filler = torch.zeros(encoder_outputs.size(0), encoder_outputs.size(1) - decoder_input_embedded.size(1), encoder_outputs.size(2))\n",
    "                decoder_input_embedded = torch.cat([decoder_input_embedded, filler], dim=1)\n",
    "                filler = torch.zeros(decoder_padding_mask.size(0), encoder_padding_mask.size(1) - decoder_padding_mask.size(1))\n",
    "                decoder_padding_mask = torch.cat([decoder_padding_mask, filler], dim=1)\n",
    "                # decoder_input_embedded = decoder_input_embedded.expand(encoder_outputs.size())\n",
    "\n",
    "                # Forward pass through model\n",
    "                outputs = model.decoder(\n",
    "                    decoder_input_embedded,\n",
    "                    encoder_outputs,\n",
    "                    causal_mask=True,\n",
    "                    # causal_mask=False,\n",
    "                    decoder_padding_mask=decoder_padding_mask,\n",
    "                    encoder_padding_mask=encoder_padding_mask\n",
    "                )\n",
    "\n",
    "                next_token_logits = outputs[:, i, :]  # (1, vocab_size)\n",
    "                next_token_probs = torch.log_softmax(next_token_logits, dim=-1).squeeze(0)\n",
    "\n",
    "                # Get top `beam_width` tokens and their log probabilities\n",
    "                topk_probs, topk_ids = torch.topk(next_token_probs, beam_width)\n",
    "\n",
    "                # Create new candidates\n",
    "                for i in range(beam_width):\n",
    "                    new_seq = torch.cat([seq, topk_ids[i].unsqueeze(0).unsqueeze(0)], dim=1)\n",
    "                    new_log_prob = cumulative_log_prob + topk_probs[i].item()\n",
    "                    all_candidates.append((new_seq, new_log_prob))\n",
    "\n",
    "            # Sort all candidates by cumulative log probability and keep the top `beam_width`\n",
    "            all_candidates = sorted(all_candidates, key=lambda x: x[1], reverse=True)\n",
    "            hypotheses = all_candidates[:beam_width]\n",
    "\n",
    "            # Check for completed hypotheses (those ending with SEP token)\n",
    "            new_hypotheses = []  # Create a new list for remaining hypotheses\n",
    "            for seq, log_prob in hypotheses:\n",
    "                if seq[0, -1].item() == tokenizer.sep_token_id:  # Use .item() to extract scalar value\n",
    "                    completed_hypotheses.append((seq, log_prob / (seq.shape[1] ** length_penalty)))  # Apply length penalty\n",
    "                else:\n",
    "                    new_hypotheses.append((seq, log_prob))  # Keep this hypothesis if not completed\n",
    "            hypotheses = new_hypotheses  # Update the hypotheses list\n",
    "\n",
    "            # If all hypotheses are completed, stop early\n",
    "            if len(hypotheses) == 0:\n",
    "                break\n",
    "        \n",
    "        # If no completed hypotheses, use the current hypotheses\n",
    "        if len(completed_hypotheses) == 0:\n",
    "            completed_hypotheses = [(h[0], h[1] / (h[0].shape[1] ** length_penalty)) for h in hypotheses]\n",
    "        \n",
    "        # Select the best hypothesis (highest log probability)\n",
    "        best_hypothesis = max(completed_hypotheses, key=lambda x: x[1])[0]\n",
    "\n",
    "        # Decode tokens into sentence\n",
    "        translated_sentence = tokenizer.decode(best_hypothesis.squeeze(0), skip_special_tokens=True)\n",
    "        return translated_sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for my local work \n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "je to najväčšia krajina.\n"
     ]
    }
   ],
   "source": [
    "print(translate_sentence(\"Slovakia is a beautiful country.\", transformer, tokenizer, device=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "po prvýmôže výzvy a po získavaní po výsledku.\n"
     ]
    }
   ],
   "source": [
    "print(translate_sentence(\"Relations between the European Union and Russia following the assassination of journalist.\", transformer, tokenizer, device=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predchádzajúcich rokovaniach o predchádzajúcom z predchádzajúcich rokov.\n"
     ]
    }
   ],
   "source": [
    "print(translate_sentence(\"Approval of Minutes of previous sitting: see Minutes.\", transformer, tokenizer, device=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "je široká krajina.\n"
     ]
    }
   ],
   "source": [
    "print(translate_sentence_beam_search(\"Slovakia is a beautiful country.\", transformer, tokenizer, device=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predchádzajúceádzaádzaádza z predádzajúceádzaádzajúádzajúádzaádzaádzajúádzaádzaádzaádzaádzaádza.\n"
     ]
    }
   ],
   "source": [
    "print(translate_sentence_beam_search(\"Approval of Minutes of previous sitting: see Minutes.\", transformer, tokenizer, device=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "project idea \\\n",
    "it can predict sequence of numbers, in words. \\\n",
    "two four six eight ten - twelve \\\n",
    "three six nine twelve - fifteen \\\n",
    "could be arithmetic and geometric. I will generate them, code up the number to string mapper, pass it mapped to strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_project_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
