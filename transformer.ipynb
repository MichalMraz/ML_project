{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michalmraz/Desktop/ML_project/ml_project_venv/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from datasets import load_dataset\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_causal_mask(seq_len):\n",
    "    # Create a matrix with ones in the lower triangle, zeros above\n",
    "    mask = torch.tril(torch.ones(seq_len, seq_len))\n",
    "    return mask  # shape (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, d_k):\n",
    "        super().__init__()\n",
    "        self.scale = d_k ** 0.5\n",
    "\n",
    "    def forward(self, Q, K, V, mask=False):\n",
    "        # Q, K, V: (batch_size, num_heads, seq_len, d_k)\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / self.scale  # (B, H, L, L)\n",
    "\n",
    "        if mask:\n",
    "            mask = generate_causal_mask(scores.size(-1)).expand(scores.size(0), scores.size(1), -1, -1)\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        attention_weights = F.softmax(scores, dim=-1)  # (B, H, L, L)\n",
    "        output = torch.matmul(attention_weights, V)    # (B, H, L, d_k)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_embedding, num_heads):\n",
    "        super().__init__()\n",
    "        assert d_embedding % num_heads == 0\n",
    "        self.d_k = d_embedding // num_heads\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        #in reality these can map to a lower dimensional space to make things faster``\n",
    "        self.W_q = nn.Linear(d_embedding, d_embedding)\n",
    "        self.W_k = nn.Linear(d_embedding, d_embedding)\n",
    "        self.W_v = nn.Linear(d_embedding, d_embedding)\n",
    "        self.W_o = nn.Linear(d_embedding, d_embedding)\n",
    "\n",
    "        self.attention = ScaledDotProductAttention(self.d_k)\n",
    "\n",
    "        self.norm = nn.LayerNorm(d_embedding)\n",
    "\n",
    "    def forward(self, x, mask=False):\n",
    "        x_input = x\n",
    "        x = self.norm(x)\n",
    "\n",
    "        B, L, d_embedding = x.size()  # Batch, Sequence Length, Embedding Dim\n",
    "        H = self.num_heads\n",
    "\n",
    "        # Linear projections\n",
    "        Q = self.W_q(x).view(B, H, L, self.d_k)  # (B, H, L, d_k)\n",
    "        K = self.W_k(x).view(B, H, L, self.d_k)\n",
    "        V = self.W_v(x).view(B, H, L, self.d_k)\n",
    "\n",
    "        # Apply attention\n",
    "        context = self.attention(Q, K, V, mask)  # (B, H, L, d_k)\n",
    "\n",
    "        # Concatenate heads\n",
    "        context = context.transpose(1, 2).contiguous().view(B, L, d_embedding)  # (B, L, d_embedding)\n",
    "\n",
    "        # Final linear projection\n",
    "        output = self.W_o(context)  # (B, L, d_embedding)\n",
    "\n",
    "        # Add (& pre-Norm)\n",
    "        #my preference is to do pre-norm for better stabiliy, even though the original paper used post-norm\n",
    "        output = x_input + output\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadCrossAttention(nn.Module):\n",
    "    def __init__(self, d_embedding, num_heads):\n",
    "        super().__init__()\n",
    "        assert d_embedding % num_heads == 0\n",
    "        self.d_k = d_embedding // num_heads\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.W_q = nn.Linear(d_embedding, d_embedding)\n",
    "        self.W_k = nn.Linear(d_embedding, d_embedding)\n",
    "        self.W_v = nn.Linear(d_embedding, d_embedding)\n",
    "        self.W_o = nn.Linear(d_embedding, d_embedding)\n",
    "\n",
    "        self.attention = ScaledDotProductAttention(self.d_k)\n",
    "\n",
    "        self.norm = nn.LayerNorm(d_embedding)\n",
    "\n",
    "    def forward(self, x_decoder, x_encoder, mask=False):\n",
    "        assert x_decoder.size() == x_encoder.size() #x and x_encoder must have the same size\n",
    "        x_input = x_decoder\n",
    "        x_decoder = self.norm(x_decoder)\n",
    "        \n",
    "        B, L, d_embedding = x_decoder.size()  # Batch, Sequence Length, Embedding Dim\n",
    "        H = self.num_heads\n",
    "\n",
    "        # Linear projections\n",
    "        Q = self.W_q(x_encoder).view(B, H, L, self.d_k)  # (B, H, L, d_k)\n",
    "        K = self.W_k(x_encoder).view(B, H, L, self.d_k)\n",
    "        V = self.W_v(x_decoder).view(B, H, L, self.d_k)\n",
    "\n",
    "        # Apply attention\n",
    "        context = self.attention(Q, K, V, mask)  # (B, H, L, d_k)\n",
    "\n",
    "        # Concatenate heads\n",
    "        context = context.transpose(1, 2).contiguous().view(B, L, d_embedding)  # (B, L, d_embedding)\n",
    "\n",
    "        # Final linear projection\n",
    "        output = self.W_o(context)  # (B, L, d_embedding)\n",
    "\n",
    "        output = output + x_input\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, d_embedding, d_ff):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_embedding, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_embedding)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.norm = nn.LayerNorm(d_embedding)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_input = x\n",
    "        x = self.norm(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        x = x_input + x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_embedding, num_heads, d_ff, num_layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            MultiHeadAttention(d_embedding, num_heads),\n",
    "            FeedForwardNetwork(d_embedding, d_ff)\n",
    "        ] * num_layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, encoder, d_embedding, num_heads, d_ff, num_layers, vocab_size):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.norm = nn.LayerNorm(d_embedding)\n",
    "        self.layers = nn.ModuleList([\n",
    "            MultiHeadAttention(d_embedding, num_heads),\n",
    "            MultiHeadCrossAttention(d_embedding, num_heads),\n",
    "            FeedForwardNetwork(d_embedding, d_ff)\n",
    "        ] * num_layers)\n",
    "        self.linear = nn.Linear(d_embedding, vocab_size)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x_decoder, x_encoder, mask=False):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if i % 3 == 0:\n",
    "                x_decoder = layer(x_decoder, mask)\n",
    "            if i % 3 == 1:\n",
    "                x_decoder = layer(x_decoder, x_encoder, mask)\n",
    "            else:\n",
    "                x_decoder = layer(x_decoder)\n",
    "        x_decoder = self.linear(x_decoder)\n",
    "        x_decoder = self.softmax(x_decoder)\n",
    "        return x_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    # chat gpt init. check if it makes sense for myself\n",
    "    # def __init__(self, d_model, max_len=5000):\n",
    "    #     super().__init__()\n",
    "\n",
    "    #     # Create a matrix of shape (max_len, d_model)\n",
    "    #     pe = torch.zeros(max_len, d_model)\n",
    "    #     position = torch.arange(0, max_len).unsqueeze(1)  # (max_len, 1)\n",
    "    #     div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "\n",
    "    #     # Apply the sine to even indices in the array; 2i\n",
    "    #     pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    #     # Apply the cosine to odd indices in the array; 2i+1\n",
    "    #     pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "    #     # Register as buffer so it's not a parameter but moves with `.to(device)`\n",
    "    #     self.register_buffer('pe', pe)\n",
    "    def __init__(self, vocab_size, d_embedding, max_len): \n",
    "        #max_len is the maximum length of the input sequence\n",
    "        super().__init__()\n",
    "        self.embedding = torch.randn(vocab_size, d_embedding)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_embedding)\n",
    "        powers = torch.repeat_interleave(torch.arange(0, 1, 2/d_embedding), repeats=2).expand(max_len, -1)\n",
    "        divisors = torch.pow(10000, powers)\n",
    "        positions = torch.arange(0, max_len).view(max_len, -1).expand(-1, d_embedding)\n",
    "        args = positions / divisors\n",
    "        pe[:, 0::2] = torch.sin(args[:, 0::2])\n",
    "        pe[:, 1::2] = torch.cos(args[:, 1::2])\n",
    "\n",
    "        # Register as buffer so it's not a parameter but moves with `.to(device)`\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor of shape (batch_size, seq_len)\n",
    "        Returns:\n",
    "            Tensor of shape (batch_size, seq_len, d_embedding)\n",
    "        \"\"\"\n",
    "        seq_len = x.size(1)\n",
    "        # Add positional encoding: broadcast over batch dimension\n",
    "        x = self.embedding[x] + self.pe[:seq_len]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 100\n",
    "max_len = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy input\n",
    "batch_size = 2\n",
    "seq_len = 5\n",
    "d_embedding = 64\n",
    "num_heads = 8\n",
    "\n",
    "x_test = torch.randn(batch_size, seq_len, d_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply attention\n",
    "mha = MultiHeadAttention(d_embedding, num_heads)\n",
    "output = mha(x_test, mask=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 64])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.ones((batch_size, seq_len, d_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 64])\n"
     ]
    }
   ],
   "source": [
    "print(output.shape)  # (2, 5, 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 64])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForwardNetwork(d_embedding, 256)\n",
    "output_2 = ffn(x_test)\n",
    "print(output_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 64])\n"
     ]
    }
   ],
   "source": [
    "d_ff = 256\n",
    "num_layers = 6\n",
    "encoder = Encoder(d_embedding, num_heads, d_ff, num_layers)\n",
    "output_3 = encoder(x_test)\n",
    "print(output_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = Embedding(vocab_size=vocab_size, d_embedding=d_embedding, max_len=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3, 64])\n"
     ]
    }
   ],
   "source": [
    "entry = torch.tensor([[1,3,4], [2,3,5]])\n",
    "print(entry.shape)\n",
    "print(embedding(entry).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_embedding, num_heads, d_ff, num_layers, max_len):\n",
    "        super().__init__()\n",
    "        self.embedding = Embedding(vocab_size, d_embedding, max_len)\n",
    "        self.encoder = Encoder(d_embedding, num_heads, d_ff, num_layers)\n",
    "        self.decoder = Decoder(self.encoder, d_embedding, num_heads, d_ff, num_layers, vocab_size)\n",
    "\n",
    "    def forward(self, x_encoder, x_decoder, mask=False):\n",
    "        x_encoder = self.embedding(x_encoder)\n",
    "        x_decoder = self.embedding(x_decoder)\n",
    "        x_encoder = self.encoder(x_encoder)\n",
    "        output = self.decoder(x_decoder, x_encoder, mask)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    vocab_size=vocab_size,\n",
    "    d_embedding=d_embedding,\n",
    "    num_heads=num_heads,\n",
    "    d_ff=d_ff,\n",
    "    num_layers=num_layers,\n",
    "    max_len=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randint(0,10,(batch_size, seq_len, d_embedding))\n",
    "x = torch.randint(0,10,(batch_size, seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 100])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer(x, x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 100])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer(x, x, True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = load_dataset('opus_books', 'en-sk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('en_sk_sentence_pairs.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_en</th>\n",
       "      <th>sentence_en</th>\n",
       "      <th>id_sk</th>\n",
       "      <th>sentence_sk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1283</td>\n",
       "      <td>The password is \"Muiriel\".</td>\n",
       "      <td>2428549</td>\n",
       "      <td>Heslo je „Muiriel“.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1317</td>\n",
       "      <td>I never liked biology.</td>\n",
       "      <td>1058173</td>\n",
       "      <td>Nikdy som nemal rád biológiu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1434</td>\n",
       "      <td>I love you.</td>\n",
       "      <td>735094</td>\n",
       "      <td>Ľúbim ťa.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1564</td>\n",
       "      <td>Thank you very much!</td>\n",
       "      <td>2428453</td>\n",
       "      <td>Ďakujem vám veľmi pekne!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1646</td>\n",
       "      <td>My name is Jack.</td>\n",
       "      <td>2428509</td>\n",
       "      <td>Volám sa Jack.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26485</th>\n",
       "      <td>13176417</td>\n",
       "      <td>Butter is a dairy product.</td>\n",
       "      <td>13173502</td>\n",
       "      <td>Maslo je mliečny produkt.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26486</th>\n",
       "      <td>13176417</td>\n",
       "      <td>Butter is a dairy product.</td>\n",
       "      <td>13173504</td>\n",
       "      <td>Maslo je mliečny výrobok.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26487</th>\n",
       "      <td>2740458</td>\n",
       "      <td>How were the pyramids built?</td>\n",
       "      <td>13177542</td>\n",
       "      <td>Ako boli postavené pyramídy?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26488</th>\n",
       "      <td>12432209</td>\n",
       "      <td>I yawn.</td>\n",
       "      <td>13180818</td>\n",
       "      <td>Zívnem.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26489</th>\n",
       "      <td>9718554</td>\n",
       "      <td>She yawned.</td>\n",
       "      <td>13180827</td>\n",
       "      <td>Zívla.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26490 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id_en                   sentence_en     id_sk  \\\n",
       "0          1283    The password is \"Muiriel\".   2428549   \n",
       "1          1317        I never liked biology.   1058173   \n",
       "2          1434                   I love you.    735094   \n",
       "3          1564          Thank you very much!   2428453   \n",
       "4          1646              My name is Jack.   2428509   \n",
       "...         ...                           ...       ...   \n",
       "26485  13176417    Butter is a dairy product.  13173502   \n",
       "26486  13176417    Butter is a dairy product.  13173504   \n",
       "26487   2740458  How were the pyramids built?  13177542   \n",
       "26488  12432209                       I yawn.  13180818   \n",
       "26489   9718554                   She yawned.  13180827   \n",
       "\n",
       "                         sentence_sk  \n",
       "0                Heslo je „Muiriel“.  \n",
       "1      Nikdy som nemal rád biológiu.  \n",
       "2                          Ľúbim ťa.  \n",
       "3           Ďakujem vám veľmi pekne!  \n",
       "4                     Volám sa Jack.  \n",
       "...                              ...  \n",
       "26485      Maslo je mliečny produkt.  \n",
       "26486      Maslo je mliečny výrobok.  \n",
       "26487   Ako boli postavené pyramídy?  \n",
       "26488                        Zívnem.  \n",
       "26489                         Zívla.  \n",
       "\n",
       "[26490 rows x 4 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")  # small, open tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# Or for BERT-style:\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = [{\n",
    "    'en': tokenizer(df.iloc[i]['sentence_en'], return_tensors='pt', padding='max_length', max_length=32, truncation=True)['input_ids'],\n",
    "    'sk': tokenizer(df.iloc[i]['sentence_sk'], return_tensors='pt', padding='max_length', max_length=32, truncation=True)['input_ids']\n",
    "} for i in range(df.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, examples, tokenizer, max_length=32):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.examples = examples\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        example = self.examples[idx]\n",
    "        inputs = self.tokenizer(example[\"input\"], return_tensors=\"pt\", padding=\"max_length\", max_length=self.max_length, truncation=True)\n",
    "        targets = self.tokenizer(example[\"target\"], return_tensors=\"pt\", padding=\"max_length\", max_length=self.max_length, truncation=True)\n",
    "        return (inputs['input_ids'], targets['input_ids'])\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": targets[\"input_ids\"].squeeze(0),\n",
    "        }\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, tokenized):\n",
    "        self.tokenized = tokenized\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.tokenized[idx]['en'], self.tokenized[idx]['sk'])\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# dataset = TranslationDataset(examples, tokenizer)\n",
    "dataset = TranslationDataset(tokenized)\n",
    "dataloader = DataLoader(dataset, batch_size=300, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "cel = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss: 4.033769607543945\n",
      "Batch Loss: 4.03731107711792\n",
      "Batch Loss: 4.044394493103027\n",
      "Batch Loss: 4.017727851867676\n",
      "Batch Loss: 4.02908182144165\n",
      "Batch Loss: 4.015956878662109\n",
      "Batch Loss: 4.0098114013671875\n",
      "Batch Loss: 4.020748615264893\n",
      "Batch Loss: 4.022207260131836\n",
      "Batch Loss: 4.019186019897461\n",
      "Batch Loss: 4.016165256500244\n",
      "Batch Loss: 4.026061058044434\n",
      "Batch Loss: 4.019290447235107\n",
      "Batch Loss: 4.035956859588623\n",
      "Batch Loss: 4.023561000823975\n",
      "Batch Loss: 4.0126237869262695\n",
      "Batch Loss: 4.006686210632324\n",
      "Batch Loss: 4.005540370941162\n",
      "Batch Loss: 4.038978099822998\n",
      "Batch Loss: 4.029811382293701\n",
      "Batch Loss: 4.023561000823975\n",
      "Batch Loss: 4.018248558044434\n",
      "Batch Loss: 4.035019397735596\n",
      "Batch Loss: 4.016582012176514\n",
      "Batch Loss: 4.019290447235107\n",
      "Batch Loss: 4.031998634338379\n",
      "Batch Loss: 4.016061305999756\n",
      "Batch Loss: 4.025019645690918\n",
      "Batch Loss: 4.034707069396973\n",
      "Batch Loss: 4.032207012176514\n",
      "Batch Loss: 4.026269435882568\n",
      "Batch Loss: 4.012832164764404\n",
      "Batch Loss: 4.005748748779297\n",
      "Batch Loss: 4.033873558044434\n",
      "Batch Loss: 4.018873691558838\n",
      "Batch Loss: 4.038248538970947\n",
      "Batch Loss: 4.012832164764404\n",
      "Batch Loss: 4.02126932144165\n",
      "Batch Loss: 4.010019302368164\n",
      "Batch Loss: 4.006165504455566\n",
      "Batch Loss: 4.025123596191406\n",
      "Batch Loss: 4.040227890014648\n",
      "Batch Loss: 4.0229363441467285\n",
      "Batch Loss: 4.014081954956055\n",
      "Batch Loss: 4.033873558044434\n",
      "Batch Loss: 4.014811038970947\n",
      "Batch Loss: 4.020331859588623\n",
      "Batch Loss: 4.014394760131836\n",
      "Batch Loss: 4.015227794647217\n",
      "Batch Loss: 4.011894702911377\n",
      "Batch Loss: 4.015436172485352\n",
      "Batch Loss: 4.016790390014648\n",
      "Batch Loss: 4.019707202911377\n",
      "Batch Loss: 4.020123481750488\n",
      "Batch Loss: 4.013665199279785\n",
      "Batch Loss: 4.018561363220215\n",
      "Batch Loss: 4.012727737426758\n",
      "Batch Loss: 4.023144721984863\n",
      "Batch Loss: 4.035852909088135\n",
      "Batch Loss: 4.011581897735596\n",
      "Batch Loss: 4.032103061676025\n",
      "Batch Loss: 4.032936096191406\n",
      "Batch Loss: 4.010644435882568\n",
      "Batch Loss: 4.021894454956055\n",
      "Batch Loss: 4.017727851867676\n",
      "Batch Loss: 4.021582126617432\n",
      "Batch Loss: 4.016582012176514\n",
      "Batch Loss: 4.018144607543945\n",
      "Batch Loss: 4.032936096191406\n",
      "Batch Loss: 4.033456802368164\n",
      "Batch Loss: 4.037936210632324\n",
      "Batch Loss: 4.017415523529053\n",
      "Batch Loss: 4.021061420440674\n",
      "Batch Loss: 4.01876974105835\n",
      "Batch Loss: 4.026998519897461\n",
      "Batch Loss: 4.030332088470459\n",
      "Batch Loss: 4.021373748779297\n",
      "Batch Loss: 4.03564453125\n",
      "Batch Loss: 4.012310981750488\n",
      "Batch Loss: 4.029186248779297\n",
      "Batch Loss: 4.010644435882568\n",
      "Batch Loss: 4.030957221984863\n",
      "Batch Loss: 4.026269435882568\n",
      "Batch Loss: 3.996894598007202\n",
      "Batch Loss: 4.01054048538208\n",
      "Batch Loss: 4.0413737297058105\n",
      "Batch Loss: 4.022207260131836\n",
      "Batch Loss: 4.018977642059326\n",
      "Batch Loss: 4.019082069396973\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence #CHECK WHAT THIS MEANS\n",
    "\n",
    "for batch_data, batch_labels in dataloader:\n",
    "    # print(batch_data.shape, batch_labels.shape)\n",
    "    batch_data = batch_data.squeeze(1)  # Remove the extra dimension\n",
    "    batch_labels = batch_labels.squeeze(1)  # Remove the extra dimension\n",
    "    batch_data = batch_data % 100\n",
    "    batch_labels = batch_labels % 100\n",
    "\n",
    "    output = transformer(batch_data, batch_data, mask=True)\n",
    "    loss = cel(output.permute(0, 2, 1), batch_labels)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Batch Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "project idea \\\n",
    "it can predict sequence of numbers, in words. \\\n",
    "two four six eight ten - twelve \\\n",
    "three six nine twelve - fifteen \\\n",
    "could be arithmetic and geometric. I will generate them, code up the number to string mapper, pass it mapped to strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_project_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
